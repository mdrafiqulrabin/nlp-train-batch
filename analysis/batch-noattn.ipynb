{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import _pickle as pk\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing imports and config... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'patience': 10,\n",
    "    'batch': 32,\n",
    "    'epoch': 100,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.99,\n",
    "    'emb_size': 64,\n",
    "    'lstm_size': 128,\n",
    "    'pred_size': 10,\n",
    "    'test_file': \"../data/raw/test.txt\",\n",
    "    'logfile': \"model_batch_noattn.log\",\n",
    "    'lossfile': 'model_batch_noattn.loss',\n",
    "    'checkpoint': \"model_batch_noattn.pt\"\n",
    "}\n",
    "\n",
    "open(config['logfile'], 'w').close()\n",
    "def saveLogMsg(msg):\n",
    "    print(msg, \"\\n\")\n",
    "    with open(config['logfile'], \"a\") as myfile:\n",
    "        myfile.write(msg + \"\\n\")\n",
    "\n",
    "saveLogMsg(\"Initializing imports and config...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for train and valid... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(1, 3)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])\n",
    "\n",
    "saveLogMsg(\"Dataset for train and valid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab for source and target... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']\n",
    "\n",
    "saveLogMsg(\"Vocab for source and target...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dataset through Vocab... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Mapping dataset through Vocab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset from ../data/raw/test.txt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(config['test_file'], delimiter='\\t', header=None, usecols=[0,1])\n",
    "test_inp, test_out = test_data[0], test_data[1]  \n",
    "\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Loading test dataset from {}.\".format(config['test_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, enc_inputs):\n",
    "        batch_inputs = copy.deepcopy(enc_inputs)\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        x_tensor = [torch.tensor(sample).to(device) for sample in batch_inputs]\n",
    "        x_pad = pad_sequence(x_tensor, batch_first=True, padding_value=0) # (batch, seqlen) \n",
    "        x_emb = self.emb(x_pad) # (batch, seqlen, emb_dim) \n",
    "        x_emb = self.drop(x_emb)\n",
    "        \n",
    "        x_len = [len(sample) for sample in batch_inputs]\n",
    "        x_pack = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
    "        outs_pack, (h_n, c_n) = self.lstm(x_pack)\n",
    "        outs, _ = pad_packed_sequence(outs_pack, batch_first=True)\n",
    "            \n",
    "        if self.z_index == 1:\n",
    "            return h_n[0], c_n[0] # (seqlen, batch, lstm_dim)\n",
    "        else:\n",
    "            return outs # (batch, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "saveLogMsg(\"encoder:\\n{}\".format(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder:\n",
      "Decoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (clf): Linear(in_features=128, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, dropout=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.clf = nn.Linear(lstm_size, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=tgt_vocab.stoi['<pad>'])\n",
    "    \n",
    "    def pad_targets(self, targets):\n",
    "        last_token = tgt_vocab.stoi['<stop>']\n",
    "        pad_token = tgt_vocab.stoi['<pad>']\n",
    "        maxlen = max([len(target) for target in targets])\n",
    "        for i in range(len(targets)): \n",
    "            targets[i].append(last_token) #added last token\n",
    "            targets[i].extend([pad_token] * (maxlen + 1 - len(targets[i]))) #added pad token\n",
    "        return targets, maxlen\n",
    "    \n",
    "    def forward(self, state, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "\n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            emb = self.drop(emb) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state \n",
    "            q_i = self.drop(q_i) # (batch, lstm_dim)\n",
    "            \n",
    "            scores = self.clf(q_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            curr_tokens = next_tokens\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        return batch_loss\n",
    "\n",
    "    def predict(self, state, curr_token, last_token, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "        \n",
    "        batch_preds = []\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            h_i, _ = state \n",
    "            \n",
    "            scores = self.clf(h_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "\n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        return batch_preds\n",
    "\n",
    "    def evaluate(self, state, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "        \n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_preds, batch_loss = [], 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            h_i, _ = state\n",
    "            \n",
    "            scores = self.clf(h_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        \n",
    "        return batch_preds, batch_loss\n",
    "\n",
    "decoder = Decoder(vocab_size=len(tgt_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'])\n",
    "saveLogMsg(\"decoder:\\n{}\".format(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    batch_x = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds = decoder.predict(encoder(batch_x), START_IX, STOP_IX, pred_size)\n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_x = []\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample_loss = 0.0\n",
    "    batch_x, batch_y = [], []\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            batch_y.append(sample_y[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds, batch_loss = decoder.evaluate(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "                \n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_y = map_prediction(batch_y)\n",
    "                actuals.extend(batch_y)\n",
    "                \n",
    "                sample_loss += batch_loss.item()\n",
    "                batch_x, batch_y = [], []\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    batch_x, batch_y = [], []\n",
    "\n",
    "    for i in range(len(train_x)):\n",
    "        batch_x.append(train_x[i])\n",
    "        batch_y.append(train_y[i])\n",
    "\n",
    "        if len(batch_x) == batch_size or i == len(train_x) - 1:\n",
    "            batch_loss = decoder(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_x, batch_y = [], []\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, '', patience_track+1\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * ', 0\n",
    "\n",
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "    decoder = Decoder(vocab_size=len(tgt_vocab),\n",
    "                      emb_dim=config['emb_size'], \n",
    "                      lstm_size=config['lstm_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "def getCurrentTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out):\n",
    "    predictions = predict(encoder, decoder, sample_x, config['batch'], config['pred_size'])\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    patience_track = 0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.zero_grad(); enc_optim.zero_grad()\n",
    "        decoder.zero_grad(); dec_optim.zero_grad()\n",
    "        \n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track, patience_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track)\n",
    "        test_acc = getAccuracyScore(encoder, decoder, test_x, test_out)\n",
    "        \n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            epoch_msg = '[{}] Epoch {}:\\n [TRAIN] Loss: {:.6f}'.format(getCurrentTime(), epoch, train_loss)\n",
    "            epoch_msg += ' [DEV] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "            epoch_msg += ' [TEST] Acc: {:.6f}'.format(test_acc)\n",
    "            saveLogMsg(epoch_msg + epoch_track)\n",
    "            \n",
    "        if patience_track == int(config['patience']):\n",
    "            saveLogMsg('No accuracy improvment for {} consecutive epochs, stopping training...'.format(config['patience']))\n",
    "            break\n",
    "    \n",
    "    best_encoder, best_decoder, _ = load_best_model()\n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    return best_encoder, best_decoder, keep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with encoder and decoder... \n",
      "\n",
      "[2020-04-09 14:18:21.513649] Epoch 1:\n",
      " [TRAIN] Loss: 1.861466 [DEV] Loss: 1.316512, Acc: 0.196200 [TEST] Acc: 0.134000 *  \n",
      "\n",
      "[2020-04-09 14:18:30.653312] Epoch 2:\n",
      " [TRAIN] Loss: 0.761363 [DEV] Loss: 0.411303, Acc: 0.756800 [TEST] Acc: 0.614400 *  \n",
      "\n",
      "[2020-04-09 14:18:39.846697] Epoch 3:\n",
      " [TRAIN] Loss: 0.364769 [DEV] Loss: 0.145832, Acc: 0.934000 [TEST] Acc: 0.817200 *  \n",
      "\n",
      "[2020-04-09 14:18:48.945683] Epoch 4:\n",
      " [TRAIN] Loss: 0.211276 [DEV] Loss: 0.084716, Acc: 0.966200 [TEST] Acc: 0.889200 *  \n",
      "\n",
      "[2020-04-09 14:18:58.098188] Epoch 5:\n",
      " [TRAIN] Loss: 0.136912 [DEV] Loss: 0.054880, Acc: 0.975800 [TEST] Acc: 0.902400 *  \n",
      "\n",
      "[2020-04-09 14:19:07.200648] Epoch 6:\n",
      " [TRAIN] Loss: 0.101041 [DEV] Loss: 0.035897, Acc: 0.990600 [TEST] Acc: 0.947800 *  \n",
      "\n",
      "[2020-04-09 14:19:16.302914] Epoch 7:\n",
      " [TRAIN] Loss: 0.080776 [DEV] Loss: 0.032049, Acc: 0.991400 [TEST] Acc: 0.947400 *  \n",
      "\n",
      "[2020-04-09 14:19:25.451808] Epoch 8:\n",
      " [TRAIN] Loss: 0.068615 [DEV] Loss: 0.026040, Acc: 0.992600 [TEST] Acc: 0.955000 *  \n",
      "\n",
      "[2020-04-09 14:19:34.555447] Epoch 9:\n",
      " [TRAIN] Loss: 0.056566 [DEV] Loss: 0.010680, Acc: 0.997400 [TEST] Acc: 0.964800 *  \n",
      "\n",
      "[2020-04-09 14:19:43.709921] Epoch 10:\n",
      " [TRAIN] Loss: 0.055300 [DEV] Loss: 0.024404, Acc: 0.992400 [TEST] Acc: 0.963200 \n",
      "\n",
      "[2020-04-09 14:19:52.801136] Epoch 11:\n",
      " [TRAIN] Loss: 0.048171 [DEV] Loss: 0.026344, Acc: 0.993600 [TEST] Acc: 0.966400 \n",
      "\n",
      "[2020-04-09 14:20:01.895220] Epoch 12:\n",
      " [TRAIN] Loss: 0.040277 [DEV] Loss: 0.024610, Acc: 0.994400 [TEST] Acc: 0.961600 \n",
      "\n",
      "[2020-04-09 14:20:11.051844] Epoch 13:\n",
      " [TRAIN] Loss: 0.039701 [DEV] Loss: 0.022080, Acc: 0.994800 [TEST] Acc: 0.960000 \n",
      "\n",
      "[2020-04-09 14:20:20.145449] Epoch 14:\n",
      " [TRAIN] Loss: 0.035591 [DEV] Loss: 0.018575, Acc: 0.992800 [TEST] Acc: 0.958800 \n",
      "\n",
      "[2020-04-09 14:20:29.300508] Epoch 15:\n",
      " [TRAIN] Loss: 0.033805 [DEV] Loss: 0.009022, Acc: 0.997400 [TEST] Acc: 0.967600 \n",
      "\n",
      "[2020-04-09 14:20:38.398217] Epoch 16:\n",
      " [TRAIN] Loss: 0.033074 [DEV] Loss: 0.009538, Acc: 0.997600 [TEST] Acc: 0.970800 *  \n",
      "\n",
      "[2020-04-09 14:20:47.493113] Epoch 17:\n",
      " [TRAIN] Loss: 0.030285 [DEV] Loss: 0.006323, Acc: 0.998400 [TEST] Acc: 0.971000 *  \n",
      "\n",
      "[2020-04-09 14:20:56.646251] Epoch 18:\n",
      " [TRAIN] Loss: 0.030334 [DEV] Loss: 0.007869, Acc: 0.997600 [TEST] Acc: 0.968400 \n",
      "\n",
      "[2020-04-09 14:21:05.741930] Epoch 19:\n",
      " [TRAIN] Loss: 0.030577 [DEV] Loss: 0.003927, Acc: 0.998600 [TEST] Acc: 0.972200 *  \n",
      "\n",
      "[2020-04-09 14:21:14.900534] Epoch 20:\n",
      " [TRAIN] Loss: 0.027847 [DEV] Loss: 0.003863, Acc: 0.999000 [TEST] Acc: 0.975800 *  \n",
      "\n",
      "[2020-04-09 14:21:23.994785] Epoch 21:\n",
      " [TRAIN] Loss: 0.029127 [DEV] Loss: 0.004316, Acc: 0.998600 [TEST] Acc: 0.975600 \n",
      "\n",
      "[2020-04-09 14:21:33.081487] Epoch 22:\n",
      " [TRAIN] Loss: 0.025518 [DEV] Loss: 0.004799, Acc: 0.998800 [TEST] Acc: 0.977200 \n",
      "\n",
      "[2020-04-09 14:21:42.219794] Epoch 23:\n",
      " [TRAIN] Loss: 0.022277 [DEV] Loss: 0.007102, Acc: 0.998200 [TEST] Acc: 0.972800 \n",
      "\n",
      "[2020-04-09 14:21:51.318761] Epoch 24:\n",
      " [TRAIN] Loss: 0.022761 [DEV] Loss: 0.002633, Acc: 0.999200 [TEST] Acc: 0.975000 *  \n",
      "\n",
      "[2020-04-09 14:22:00.468263] Epoch 25:\n",
      " [TRAIN] Loss: 0.022107 [DEV] Loss: 0.003649, Acc: 0.999000 [TEST] Acc: 0.975800 \n",
      "\n",
      "[2020-04-09 14:22:09.554841] Epoch 26:\n",
      " [TRAIN] Loss: 0.022461 [DEV] Loss: 0.001011, Acc: 0.999800 [TEST] Acc: 0.978000 *  \n",
      "\n",
      "[2020-04-09 14:22:18.693529] Epoch 27:\n",
      " [TRAIN] Loss: 0.021539 [DEV] Loss: 0.003235, Acc: 0.999000 [TEST] Acc: 0.977600 \n",
      "\n",
      "[2020-04-09 14:22:27.784739] Epoch 28:\n",
      " [TRAIN] Loss: 0.023791 [DEV] Loss: 0.006301, Acc: 0.998800 [TEST] Acc: 0.974000 \n",
      "\n",
      "[2020-04-09 14:22:36.870734] Epoch 29:\n",
      " [TRAIN] Loss: 0.022807 [DEV] Loss: 0.005625, Acc: 0.998600 [TEST] Acc: 0.977000 \n",
      "\n",
      "[2020-04-09 14:22:46.024066] Epoch 30:\n",
      " [TRAIN] Loss: 0.022011 [DEV] Loss: 0.013153, Acc: 0.997000 [TEST] Acc: 0.974800 \n",
      "\n",
      "[2020-04-09 14:22:55.112003] Epoch 31:\n",
      " [TRAIN] Loss: 0.021047 [DEV] Loss: 0.004532, Acc: 0.998800 [TEST] Acc: 0.977200 \n",
      "\n",
      "[2020-04-09 14:23:04.261929] Epoch 32:\n",
      " [TRAIN] Loss: 0.019016 [DEV] Loss: 0.009353, Acc: 0.997400 [TEST] Acc: 0.973200 \n",
      "\n",
      "[2020-04-09 14:23:13.352048] Epoch 33:\n",
      " [TRAIN] Loss: 0.020208 [DEV] Loss: 0.004496, Acc: 0.999000 [TEST] Acc: 0.975400 \n",
      "\n",
      "[2020-04-09 14:23:22.440114] Epoch 34:\n",
      " [TRAIN] Loss: 0.020166 [DEV] Loss: 0.006814, Acc: 0.998400 [TEST] Acc: 0.976800 \n",
      "\n",
      "[2020-04-09 14:23:31.589668] Epoch 35:\n",
      " [TRAIN] Loss: 0.020370 [DEV] Loss: 0.002410, Acc: 0.999400 [TEST] Acc: 0.974200 \n",
      "\n",
      "[2020-04-09 14:23:40.678760] Epoch 36:\n",
      " [TRAIN] Loss: 0.019524 [DEV] Loss: 0.002740, Acc: 0.999400 [TEST] Acc: 0.975000 \n",
      "\n",
      "No accuracy improvment for 10 consecutive epochs, stopping training... \n",
      "\n",
      "Training done... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True: #not os.path.exists(config['checkpoint']):\n",
    "    saveLogMsg(\"Training with encoder and decoder...\")\n",
    "    training_loop(encoder, decoder, train_x, train_y, config['epoch'], config['batch'], print_every=1)\n",
    "    saveLogMsg('Training done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning best model from epoch 26 with loss 0.001011 and accuracy 0.999800. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "encoder, decoder, state = load_best_model()\n",
    "saveLogMsg('Returning best model from epoch {} with loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training and validation loss... \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveLogMsg('Retrieving training and validation loss...')\n",
    "\n",
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "\n",
    "# Refs: https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
