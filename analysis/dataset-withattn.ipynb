{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import _pickle as pk\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing imports and config... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'patience': 10,\n",
    "    'batch': 32,\n",
    "    'epoch': 100,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.99,\n",
    "    'emb_size': 64,\n",
    "    'lstm_size': 128,\n",
    "    'attn_size': 100,\n",
    "    'pred_size': 10,\n",
    "    'test_file': \"../data/raw/test.txt\",\n",
    "    'logfile': \"dataset-batch-withattn.log\",\n",
    "    'lossfile': 'dataset-batch-withattn.loss',\n",
    "    'checkpoint': \"dataset-batch-withattn.pt\"\n",
    "}\n",
    "\n",
    "open(config['logfile'], 'w').close()\n",
    "def saveLogMsg(msg):\n",
    "    print(msg, \"\\n\")\n",
    "    with open(config['logfile'], \"a\") as myfile:\n",
    "        myfile.write(msg + \"\\n\")\n",
    "\n",
    "saveLogMsg(\"Initializing imports and config...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for train and valid... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(5, 10)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])\n",
    "\n",
    "saveLogMsg(\"Dataset for train and valid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab for source and target... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']\n",
    "\n",
    "saveLogMsg(\"Vocab for source and target...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dataset through Vocab... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Mapping dataset through Vocab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset from ../data/raw/test.txt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(config['test_file'], delimiter='\\t', header=None, usecols=[0,1])\n",
    "test_inp, test_out = test_data[0], test_data[1]  \n",
    "\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Loading test dataset from {}.\".format(config['test_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, enc_inputs):\n",
    "        batch_inputs = copy.deepcopy(enc_inputs)\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        x_tensor = [torch.tensor(sample).to(device) for sample in batch_inputs]\n",
    "        x_pad = pad_sequence(x_tensor, batch_first=True, padding_value=0) # (batch, seqlen) \n",
    "        x_emb = self.emb(x_pad) # (batch, seqlen, emb_dim) \n",
    "        x_emb = self.drop(x_emb)\n",
    "        \n",
    "        x_len = [len(sample) for sample in batch_inputs]\n",
    "        x_pack = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
    "        outs_pack, (h_n, c_n) = self.lstm(x_pack)\n",
    "        outs, _ = pad_packed_sequence(outs_pack, batch_first=True)\n",
    "            \n",
    "        if self.z_index == 1:\n",
    "            return h_n[0], c_n[0] # (seqlen, batch, lstm_dim)\n",
    "        else:\n",
    "            return outs # (batch, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=0)\n",
    "saveLogMsg(\"encoder:\\n{}\".format(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, attn_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W = nn.Linear(input_dim, attn_dim)\n",
    "        self.v = nn.Linear(attn_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, dec_hidden, enc_outs):\n",
    "        # enc_outs -> (batch, seqlen, hidden)\n",
    "        # dec_hidden -> (batch, hidden)\n",
    "        \n",
    "        seqlen = enc_outs.size(1)\n",
    "        \n",
    "        repeat_h = dec_hidden.unsqueeze(1)  # make room to repeat on seqlen dim\n",
    "        repeat_h = repeat_h.repeat(1, seqlen, 1)  # (1, seqlen, hidden)\n",
    "\n",
    "        concat_h = torch.cat((enc_outs, repeat_h), dim=2) # (1, seqlen, hidden*2)\n",
    "        \n",
    "        scores = self.v(torch.tanh(self.W(concat_h))) # (1, seqlen, 1)\n",
    "        probs = torch.softmax(scores, dim=1)\n",
    "        \n",
    "        weighted = enc_outs * probs # (1, seqlen, hidden)\n",
    "        \n",
    "        context = torch.sum(weighted, dim=1, keepdim=False) # (1, hidden)\n",
    "        combined = torch.cat((dec_hidden, context), dim=1)  # (1, hidden*2)\n",
    "        \n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder:\n",
      "AttentionDecoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (attn): Attention(\n",
      "    (W): Linear(in_features=256, out_features=100, bias=True)\n",
      "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=256, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, attn_size, dropout=0.5):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        \n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.attn = Attention(lstm_size * 2, attn_size)\n",
    "        self.clf = nn.Linear(lstm_size * 2, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=tgt_vocab.stoi['<pad>'])\n",
    "        \n",
    "    def init_state(self, batch_size, device):\n",
    "        h_0 = torch.zeros(batch_size, self.lstm_size).to(device)  # (batch, hidden_size)\n",
    "        c_0 = torch.zeros(batch_size, self.lstm_size).to(device)  # (batch, hidden_size)\n",
    "        return h_0, c_0\n",
    "    \n",
    "    def pad_targets(self, targets):\n",
    "        last_token = tgt_vocab.stoi['<stop>']\n",
    "        pad_token = tgt_vocab.stoi['<pad>']\n",
    "        maxlen = max([len(target) for target in targets])\n",
    "        for i in range(len(targets)): \n",
    "            targets[i].append(last_token) #added last token\n",
    "            targets[i].extend([pad_token] * (maxlen + 1 - len(targets[i]))) #added pad token\n",
    "        return targets, maxlen\n",
    "            \n",
    "    def forward(self, enc_outs, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = enc_outs.shape[0]\n",
    "        state = self.init_state(batch_size, device) # (batch, lstm_dim)\n",
    "        \n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            emb = self.drop(emb) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state \n",
    "            q_i = self.drop(q_i) # (batch, lstm_dim)\n",
    "            \n",
    "            combined = self.attn(q_i, enc_outs) # (batch, lstm_dim * 2)\n",
    "            scores = self.clf(combined) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            curr_tokens = next_tokens\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        return batch_loss\n",
    "    \n",
    "    def predict(self, enc_outs, curr_token, last_token, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = enc_outs.shape[0]\n",
    "        state = self.init_state(batch_size, device) # (batch, lstm_dim)\n",
    "        \n",
    "        batch_preds = []\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state \n",
    "            \n",
    "            combined = self.attn(q_i, enc_outs) # (batch, lstm_dim * 2)\n",
    "            scores = self.clf(combined) # (batch, tgt_vocab)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "\n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        return batch_preds\n",
    "    \n",
    "    def evaluate(self, enc_outs, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = enc_outs.shape[0]\n",
    "        state = self.init_state(batch_size, device) # (batch, lstm_dim)\n",
    "        \n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_preds, batch_loss = [], 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state\n",
    "            \n",
    "            combined = self.attn(q_i, enc_outs) # (batch, lstm_dim * 2)\n",
    "            scores = self.clf(combined) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        \n",
    "        return batch_preds, batch_loss\n",
    "\n",
    "decoder = AttentionDecoder(vocab_size=len(tgt_vocab), \n",
    "                           emb_dim=config['emb_size'], \n",
    "                           lstm_size=config['lstm_size'], \n",
    "                           attn_size=config['attn_size'])\n",
    "saveLogMsg(\"decoder:\\n{}\".format(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    batch_x = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds = decoder.predict(encoder(batch_x), START_IX, STOP_IX, pred_size)\n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_x = []\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample_loss = 0.0\n",
    "    batch_x, batch_y = [], []\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            batch_y.append(sample_y[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds, batch_loss = decoder.evaluate(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "                \n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_y = map_prediction(batch_y)\n",
    "                actuals.extend(batch_y)\n",
    "                \n",
    "                sample_loss += batch_loss.item()\n",
    "                batch_x, batch_y = [], []\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    batch_x, batch_y = [], []\n",
    "\n",
    "    for i in range(len(train_x)):\n",
    "        batch_x.append(train_x[i])\n",
    "        batch_y.append(train_y[i])\n",
    "\n",
    "        if len(batch_x) == batch_size or i == len(train_x) - 1:\n",
    "            batch_loss = decoder(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_x, batch_y = [], []\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, '', patience_track+1\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * ', 0\n",
    "\n",
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=0)\n",
    "    decoder = AttentionDecoder(vocab_size=len(tgt_vocab), \n",
    "                               emb_dim=config['emb_size'], \n",
    "                               lstm_size=config['lstm_size'], \n",
    "                               attn_size=config['attn_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "def getCurrentTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out):\n",
    "    predictions = predict(encoder, decoder, sample_x, config['batch'], config['pred_size'])\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    patience_track = 0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.zero_grad(); enc_optim.zero_grad()\n",
    "        decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track, patience_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track)\n",
    "        test_acc = getAccuracyScore(encoder, decoder, test_x, test_out)\n",
    "        \n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            epoch_msg = '[{}] Epoch {}:\\n [TRAIN] Loss: {:.6f}'.format(getCurrentTime(), epoch, train_loss)\n",
    "            epoch_msg += ' [DEV] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "            epoch_msg += ' [TEST] Acc: {:.6f}'.format(test_acc)\n",
    "            saveLogMsg(epoch_msg + epoch_track)\n",
    "            \n",
    "        if patience_track == int(config['patience']):\n",
    "            saveLogMsg('No accuracy improvment for {} consecutive epochs, stopping training...'.format(config['patience']))\n",
    "            break\n",
    "    \n",
    "    best_encoder, best_decoder, _ = load_best_model()\n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    return best_encoder, best_decoder, keep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with encoder and decoder... \n",
      "\n",
      "[2020-04-10 04:50:53.099771] Epoch 1:\n",
      " [TRAIN] Loss: 1.172598 [DEV] Loss: 0.929363, Acc: 0.853200 [TEST] Acc: 0.408400 *  \n",
      "\n",
      "[2020-04-10 04:51:15.140050] Epoch 2:\n",
      " [TRAIN] Loss: 0.182539 [DEV] Loss: 0.198643, Acc: 0.953200 [TEST] Acc: 0.585400 *  \n",
      "\n",
      "[2020-04-10 04:51:43.783857] Epoch 3:\n",
      " [TRAIN] Loss: 0.121971 [DEV] Loss: 0.235540, Acc: 0.967400 [TEST] Acc: 0.667400 *  \n",
      "\n",
      "[2020-04-10 04:52:15.580619] Epoch 4:\n",
      " [TRAIN] Loss: 0.092493 [DEV] Loss: 0.255414, Acc: 0.967400 [TEST] Acc: 0.694000 \n",
      "\n",
      "[2020-04-10 04:52:46.590562] Epoch 5:\n",
      " [TRAIN] Loss: 0.077760 [DEV] Loss: 0.108636, Acc: 0.988000 [TEST] Acc: 0.720000 *  \n",
      "\n",
      "[2020-04-10 04:53:18.402740] Epoch 6:\n",
      " [TRAIN] Loss: 0.067475 [DEV] Loss: 0.071802, Acc: 0.992000 [TEST] Acc: 0.732800 *  \n",
      "\n",
      "[2020-04-10 04:53:49.463127] Epoch 7:\n",
      " [TRAIN] Loss: 0.065166 [DEV] Loss: 0.114315, Acc: 0.985400 [TEST] Acc: 0.759400 \n",
      "\n",
      "[2020-04-10 04:54:21.286366] Epoch 8:\n",
      " [TRAIN] Loss: 0.059683 [DEV] Loss: 0.078822, Acc: 0.988200 [TEST] Acc: 0.760600 \n",
      "\n",
      "[2020-04-10 04:54:52.450467] Epoch 9:\n",
      " [TRAIN] Loss: 0.049828 [DEV] Loss: 0.101747, Acc: 0.987200 [TEST] Acc: 0.761800 \n",
      "\n",
      "[2020-04-10 04:55:24.099896] Epoch 10:\n",
      " [TRAIN] Loss: 0.051775 [DEV] Loss: 0.037362, Acc: 0.994400 [TEST] Acc: 0.812800 *  \n",
      "\n",
      "[2020-04-10 04:55:55.468904] Epoch 11:\n",
      " [TRAIN] Loss: 0.046773 [DEV] Loss: 0.089983, Acc: 0.989600 [TEST] Acc: 0.735600 \n",
      "\n",
      "[2020-04-10 04:56:26.774171] Epoch 12:\n",
      " [TRAIN] Loss: 0.043615 [DEV] Loss: 0.057781, Acc: 0.991800 [TEST] Acc: 0.785000 \n",
      "\n",
      "[2020-04-10 04:56:58.437641] Epoch 13:\n",
      " [TRAIN] Loss: 0.042910 [DEV] Loss: 0.027386, Acc: 0.994600 [TEST] Acc: 0.767000 *  \n",
      "\n",
      "[2020-04-10 04:57:29.546965] Epoch 14:\n",
      " [TRAIN] Loss: 0.043367 [DEV] Loss: 0.047252, Acc: 0.994200 [TEST] Acc: 0.740200 \n",
      "\n",
      "[2020-04-10 04:58:01.429441] Epoch 15:\n",
      " [TRAIN] Loss: 0.039451 [DEV] Loss: 0.012169, Acc: 0.997600 [TEST] Acc: 0.769600 *  \n",
      "\n",
      "[2020-04-10 04:58:32.411403] Epoch 16:\n",
      " [TRAIN] Loss: 0.034635 [DEV] Loss: 0.018846, Acc: 0.996800 [TEST] Acc: 0.750400 \n",
      "\n",
      "[2020-04-10 04:58:59.399089] Epoch 17:\n",
      " [TRAIN] Loss: 0.035971 [DEV] Loss: 0.019057, Acc: 0.997000 [TEST] Acc: 0.764800 \n",
      "\n",
      "[2020-04-10 04:59:21.507741] Epoch 18:\n",
      " [TRAIN] Loss: 0.035402 [DEV] Loss: 0.026679, Acc: 0.996800 [TEST] Acc: 0.754200 \n",
      "\n",
      "[2020-04-10 04:59:43.574385] Epoch 19:\n",
      " [TRAIN] Loss: 0.031037 [DEV] Loss: 0.022721, Acc: 0.995400 [TEST] Acc: 0.779000 \n",
      "\n",
      "[2020-04-10 05:00:05.704011] Epoch 20:\n",
      " [TRAIN] Loss: 0.035146 [DEV] Loss: 0.029218, Acc: 0.995000 [TEST] Acc: 0.769800 \n",
      "\n",
      "[2020-04-10 05:00:27.741381] Epoch 21:\n",
      " [TRAIN] Loss: 0.031408 [DEV] Loss: 0.071108, Acc: 0.991800 [TEST] Acc: 0.742400 \n",
      "\n",
      "[2020-04-10 05:00:49.852393] Epoch 22:\n",
      " [TRAIN] Loss: 0.032429 [DEV] Loss: 0.026753, Acc: 0.994000 [TEST] Acc: 0.774800 \n",
      "\n",
      "[2020-04-10 05:01:11.915457] Epoch 23:\n",
      " [TRAIN] Loss: 0.030103 [DEV] Loss: 0.026079, Acc: 0.996400 [TEST] Acc: 0.747200 \n",
      "\n",
      "[2020-04-10 05:01:33.976909] Epoch 24:\n",
      " [TRAIN] Loss: 0.028059 [DEV] Loss: 0.041289, Acc: 0.992000 [TEST] Acc: 0.765000 \n",
      "\n",
      "[2020-04-10 05:01:56.089437] Epoch 25:\n",
      " [TRAIN] Loss: 0.031720 [DEV] Loss: 0.035435, Acc: 0.996200 [TEST] Acc: 0.783400 \n",
      "\n",
      "No accuracy improvment for 10 consecutive epochs, stopping training... \n",
      "\n",
      "Training done... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True: #not os.path.exists(config['checkpoint']):\n",
    "    saveLogMsg(\"Training with encoder and decoder...\")\n",
    "    training_loop(encoder, decoder, train_x, train_y, config['epoch'], config['batch'], print_every=1)\n",
    "    saveLogMsg('Training done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning best model from epoch 15 with loss 0.012169 and accuracy 0.997600. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "encoder, decoder, state = load_best_model()\n",
    "saveLogMsg('Returning best model from epoch {} with loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training and validation loss... \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveLogMsg('Retrieving training and validation loss...')\n",
    "\n",
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "\n",
    "# Refs: https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
