{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "import _pickle as pk\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'pred_maxlen': 10,\n",
    "    \n",
    "    'lr': 0.001,\n",
    "    'mt': 0.99,\n",
    "    'emb_dim': 64,\n",
    "    'lstm_size': 128,\n",
    "    'attn_size': 100,\n",
    "    'dropout': 0.5,\n",
    "    'batch': 32,\n",
    "    'epoch': 50,\n",
    "    \n",
    "    'testfile': \"test.txt\",\n",
    "    'lossfile': 'model_noattn.loss',\n",
    "    'checkpoint': \"model_noattn.pt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(1, 3)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training dataset: 20000\n",
      "Length of the validation dataset: 5000\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "print(\"Length of the training dataset: {}\".format(len(train_x)))\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "print(\"Length of the validation dataset: {}\".format(len(valid_x)))\n",
    "\n",
    "PAD_IX   = tgt_vocab.stoi['<pad>']\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, enc_inputs):\n",
    "        batch_inputs = copy.deepcopy(enc_inputs)\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        x_tensor = [torch.tensor(sample).to(device) for sample in batch_inputs]\n",
    "        x_pad = pad_sequence(x_tensor, batch_first=True, padding_value=0) # (batch, seqlen) \n",
    "        x_emb = self.emb(x_pad) # (batch, seqlen, emb_dim) \n",
    "        x_emb = self.drop(x_emb)\n",
    "        \n",
    "        x_len = [len(sample) for sample in batch_inputs]\n",
    "        x_pack = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
    "        outs_pack, (h_n, c_n) = self.lstm(x_pack)\n",
    "        outs, _ = pad_packed_sequence(outs_pack, batch_first=True)\n",
    "            \n",
    "        if self.z_index == 1:\n",
    "            return h_n[0], c_n[0] # (seqlen, batch, lstm_dim)\n",
    "        else:\n",
    "            return outs # (batch, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_dim'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (clf): Linear(in_features=128, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, dropout=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.clf = nn.Linear(lstm_size, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=tgt_vocab.stoi['<pad>'])\n",
    "    \n",
    "    def pad_targets(self, targets):\n",
    "        last_token = tgt_vocab.stoi['<stop>']\n",
    "        pad_token = tgt_vocab.stoi['<pad>']\n",
    "        maxlen = max([len(target) for target in targets])\n",
    "        for i in range(len(targets)): \n",
    "            targets[i].append(last_token) #added last token\n",
    "            targets[i].extend([pad_token] * (maxlen + 1 - len(targets[i]))) #added pad token\n",
    "        return targets, maxlen\n",
    "    \n",
    "    def forward(self, state, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "\n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            emb = self.drop(emb) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state \n",
    "            q_i = self.drop(q_i) # (batch, lstm_dim)\n",
    "            \n",
    "            scores = self.clf(q_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            curr_tokens = next_tokens\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        return batch_loss\n",
    "\n",
    "    def predict(self, state, curr_token, last_token, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "        \n",
    "        batch_preds = []\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            h_i, _ = state \n",
    "            \n",
    "            scores = self.clf(h_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "\n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        return batch_preds\n",
    "\n",
    "    def evaluate(self, state, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "        \n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_preds, batch_loss = [], 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            h_i, _ = state\n",
    "            \n",
    "            scores = self.clf(h_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        \n",
    "        return batch_preds, batch_loss\n",
    "\n",
    "decoder = Decoder(vocab_size=len(tgt_vocab), \n",
    "                  emb_dim=config['emb_dim'], \n",
    "                  lstm_size=config['lstm_size'])\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample_loss = 0.0\n",
    "    batch_x, batch_y = [], []\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            batch_y.append(sample_y[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds, batch_loss = decoder.evaluate(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "                \n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_y = map_prediction(batch_y)\n",
    "                actuals.extend(batch_y)\n",
    "                \n",
    "                sample_loss += batch_loss.item()\n",
    "                batch_x, batch_y = [], []\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    batch_x, batch_y = [], []\n",
    "\n",
    "    for i in range(len(train_x)):\n",
    "        batch_x.append(train_x[i])\n",
    "        batch_y.append(train_y[i])\n",
    "\n",
    "        if len(batch_x) == batch_size or i == len(train_x) - 1:\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "        \n",
    "            batch_loss = decoder(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_x, batch_y = [], []\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, ''\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * '\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    print(\"\\nTraining with encoder and decoder...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"\\nAttaching to device: {}\".format(device))\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['mt'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['mt'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss)\n",
    "\n",
    "        \n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        epoch_msg = '\\n[{}] Epoch {:02d}: [TRAIN] Loss: {:.6f}'.format(getCurrentTime(), epoch, train_loss)\n",
    "        epoch_msg += ' [VAL] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "        print(epoch_msg + epoch_track)\n",
    "    \n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    print(\"\\nTraining completed...\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with encoder and decoder...\n",
      "\n",
      "Attaching to device: cuda\n",
      "\n",
      "[2020-04-11 16:49:00.756264] Epoch 01: [TRAIN] Loss: 1.861466 [VAL] Loss: 1.316512, Acc: 0.196200 * \n",
      "\n",
      "[2020-04-11 16:49:09.398111] Epoch 02: [TRAIN] Loss: 0.761363 [VAL] Loss: 0.411303, Acc: 0.756800 * \n",
      "\n",
      "[2020-04-11 16:49:17.972774] Epoch 03: [TRAIN] Loss: 0.364769 [VAL] Loss: 0.145832, Acc: 0.934000 * \n",
      "\n",
      "[2020-04-11 16:49:26.607936] Epoch 04: [TRAIN] Loss: 0.211276 [VAL] Loss: 0.084716, Acc: 0.966200 * \n",
      "\n",
      "[2020-04-11 16:49:35.170264] Epoch 05: [TRAIN] Loss: 0.136912 [VAL] Loss: 0.054880, Acc: 0.975800 * \n",
      "\n",
      "[2020-04-11 16:49:43.739811] Epoch 06: [TRAIN] Loss: 0.101041 [VAL] Loss: 0.035897, Acc: 0.990600 * \n",
      "\n",
      "[2020-04-11 16:49:52.379275] Epoch 07: [TRAIN] Loss: 0.080776 [VAL] Loss: 0.032049, Acc: 0.991400 * \n",
      "\n",
      "[2020-04-11 16:50:00.950659] Epoch 08: [TRAIN] Loss: 0.068615 [VAL] Loss: 0.026040, Acc: 0.992600 * \n",
      "\n",
      "[2020-04-11 16:50:09.596581] Epoch 09: [TRAIN] Loss: 0.056566 [VAL] Loss: 0.010680, Acc: 0.997400 * \n",
      "\n",
      "[2020-04-11 16:50:18.172467] Epoch 10: [TRAIN] Loss: 0.055300 [VAL] Loss: 0.024404, Acc: 0.992400\n",
      "\n",
      "[2020-04-11 16:50:26.744280] Epoch 11: [TRAIN] Loss: 0.048171 [VAL] Loss: 0.026344, Acc: 0.993600\n",
      "\n",
      "[2020-04-11 16:50:35.385126] Epoch 12: [TRAIN] Loss: 0.040277 [VAL] Loss: 0.024610, Acc: 0.994400\n",
      "\n",
      "[2020-04-11 16:50:43.954479] Epoch 13: [TRAIN] Loss: 0.039701 [VAL] Loss: 0.022080, Acc: 0.994800\n",
      "\n",
      "[2020-04-11 16:50:52.583714] Epoch 14: [TRAIN] Loss: 0.035591 [VAL] Loss: 0.018575, Acc: 0.992800\n",
      "\n",
      "[2020-04-11 16:51:01.154012] Epoch 15: [TRAIN] Loss: 0.033805 [VAL] Loss: 0.009022, Acc: 0.997400\n",
      "\n",
      "[2020-04-11 16:51:09.727430] Epoch 16: [TRAIN] Loss: 0.033074 [VAL] Loss: 0.009538, Acc: 0.997600 * \n",
      "\n",
      "[2020-04-11 16:51:18.369043] Epoch 17: [TRAIN] Loss: 0.030285 [VAL] Loss: 0.006323, Acc: 0.998400 * \n",
      "\n",
      "[2020-04-11 16:51:26.933627] Epoch 18: [TRAIN] Loss: 0.030334 [VAL] Loss: 0.007869, Acc: 0.997600\n",
      "\n",
      "[2020-04-11 16:51:35.562134] Epoch 19: [TRAIN] Loss: 0.030577 [VAL] Loss: 0.003927, Acc: 0.998600 * \n",
      "\n",
      "[2020-04-11 16:51:44.139106] Epoch 20: [TRAIN] Loss: 0.027847 [VAL] Loss: 0.003863, Acc: 0.999000 * \n",
      "\n",
      "[2020-04-11 16:51:52.768207] Epoch 21: [TRAIN] Loss: 0.029127 [VAL] Loss: 0.004316, Acc: 0.998600\n",
      "\n",
      "[2020-04-11 16:52:01.318094] Epoch 22: [TRAIN] Loss: 0.025518 [VAL] Loss: 0.004799, Acc: 0.998800\n",
      "\n",
      "[2020-04-11 16:52:09.872171] Epoch 23: [TRAIN] Loss: 0.022277 [VAL] Loss: 0.007102, Acc: 0.998200\n",
      "\n",
      "[2020-04-11 16:52:18.517192] Epoch 24: [TRAIN] Loss: 0.022761 [VAL] Loss: 0.002633, Acc: 0.999200 * \n",
      "\n",
      "[2020-04-11 16:52:27.083996] Epoch 25: [TRAIN] Loss: 0.022107 [VAL] Loss: 0.003649, Acc: 0.999000\n",
      "\n",
      "[2020-04-11 16:52:35.676799] Epoch 26: [TRAIN] Loss: 0.022461 [VAL] Loss: 0.001011, Acc: 0.999800 * \n",
      "\n",
      "[2020-04-11 16:52:44.194796] Epoch 27: [TRAIN] Loss: 0.021539 [VAL] Loss: 0.003235, Acc: 0.999000\n",
      "\n",
      "[2020-04-11 16:52:52.726169] Epoch 28: [TRAIN] Loss: 0.023791 [VAL] Loss: 0.006301, Acc: 0.998800\n",
      "\n",
      "[2020-04-11 16:53:01.351753] Epoch 29: [TRAIN] Loss: 0.022807 [VAL] Loss: 0.005625, Acc: 0.998600\n",
      "\n",
      "[2020-04-11 16:53:09.911702] Epoch 30: [TRAIN] Loss: 0.022011 [VAL] Loss: 0.013153, Acc: 0.997000\n",
      "\n",
      "[2020-04-11 16:53:18.542512] Epoch 31: [TRAIN] Loss: 0.021047 [VAL] Loss: 0.004532, Acc: 0.998800\n",
      "\n",
      "[2020-04-11 16:53:27.107499] Epoch 32: [TRAIN] Loss: 0.019016 [VAL] Loss: 0.009353, Acc: 0.997400\n",
      "\n",
      "[2020-04-11 16:53:35.673928] Epoch 33: [TRAIN] Loss: 0.020208 [VAL] Loss: 0.004496, Acc: 0.999000\n",
      "\n",
      "[2020-04-11 16:53:44.304777] Epoch 34: [TRAIN] Loss: 0.020166 [VAL] Loss: 0.006814, Acc: 0.998400\n",
      "\n",
      "[2020-04-11 16:53:52.861057] Epoch 35: [TRAIN] Loss: 0.020370 [VAL] Loss: 0.002410, Acc: 0.999400\n",
      "\n",
      "[2020-04-11 16:54:01.477381] Epoch 36: [TRAIN] Loss: 0.019524 [VAL] Loss: 0.002740, Acc: 0.999400\n",
      "\n",
      "[2020-04-11 16:54:10.016627] Epoch 37: [TRAIN] Loss: 0.018302 [VAL] Loss: 0.007389, Acc: 0.998600\n",
      "\n",
      "[2020-04-11 16:54:18.576194] Epoch 38: [TRAIN] Loss: 0.017279 [VAL] Loss: 0.003094, Acc: 0.999200\n",
      "\n",
      "[2020-04-11 16:54:27.202331] Epoch 39: [TRAIN] Loss: 0.016560 [VAL] Loss: 0.002703, Acc: 0.999400\n",
      "\n",
      "[2020-04-11 16:54:35.758737] Epoch 40: [TRAIN] Loss: 0.018062 [VAL] Loss: 0.002092, Acc: 0.999400\n",
      "\n",
      "[2020-04-11 16:54:44.381154] Epoch 41: [TRAIN] Loss: 0.017785 [VAL] Loss: 0.003217, Acc: 0.999400\n",
      "\n",
      "[2020-04-11 16:54:52.932963] Epoch 42: [TRAIN] Loss: 0.018048 [VAL] Loss: 0.002020, Acc: 0.999600\n",
      "\n",
      "[2020-04-11 16:55:01.485895] Epoch 43: [TRAIN] Loss: 0.019450 [VAL] Loss: 0.007101, Acc: 0.998600\n",
      "\n",
      "[2020-04-11 16:55:10.102925] Epoch 44: [TRAIN] Loss: 0.021928 [VAL] Loss: 0.004354, Acc: 0.999000\n",
      "\n",
      "[2020-04-11 16:55:18.643663] Epoch 45: [TRAIN] Loss: 0.020575 [VAL] Loss: 0.007791, Acc: 0.998000\n",
      "\n",
      "[2020-04-11 16:55:27.244791] Epoch 46: [TRAIN] Loss: 0.018446 [VAL] Loss: 0.004865, Acc: 0.999000\n",
      "\n",
      "[2020-04-11 16:55:35.786881] Epoch 47: [TRAIN] Loss: 0.016230 [VAL] Loss: 0.003909, Acc: 0.999000\n",
      "\n",
      "[2020-04-11 16:55:44.339437] Epoch 48: [TRAIN] Loss: 0.017046 [VAL] Loss: 0.004533, Acc: 0.999200\n",
      "\n",
      "[2020-04-11 16:55:52.951297] Epoch 49: [TRAIN] Loss: 0.016236 [VAL] Loss: 0.005570, Acc: 0.999000\n",
      "\n",
      "[2020-04-11 16:56:01.496036] Epoch 50: [TRAIN] Loss: 0.014965 [VAL] Loss: 0.006835, Acc: 0.998400\n",
      "\n",
      "Training completed...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(config['checkpoint']):\n",
    "    training_loop(encoder, decoder, train_x, train_y, config['epoch'], config['batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving best model from epoch 26 with [DEV] loss 0.001011 and accuracy 0.999800.\n"
     ]
    }
   ],
   "source": [
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_dim'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "    decoder = Decoder(vocab_size=len(tgt_vocab),\n",
    "                      emb_dim=config['emb_dim'], \n",
    "                      lstm_size=config['lstm_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "encoder, decoder, state = load_best_model()\n",
    "print('Retrieving best model from epoch {} with [DEV] loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the test dataset: 5000\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(config['testfile'], delimiter='\\t', header=None, usecols=[0,1])\n",
    "test_inp, test_out = test_data[0], test_data[1]  \n",
    "\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)\n",
    "\n",
    "print(\"Length of the test dataset: {}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (max prediction size = 10) = 97.80%\n",
      "Accuracy on the test set (max prediction size = 20) = 99.70%\n"
     ]
    }
   ],
   "source": [
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    batch_x = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds = decoder.predict(encoder(batch_x), START_IX, STOP_IX, pred_size)\n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_x = []\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out, batch_size, pred_size):\n",
    "    predictions = predict(encoder, decoder, sample_x, batch_size, pred_size)\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "config['pred_maxlen'] = 10\n",
    "test_acc = getAccuracyScore(encoder, decoder, test_x, test_out, config['batch'], config['pred_maxlen']) * 100\n",
    "print('Accuracy on the test set (max prediction size = {}) = {:.2f}%'.format(config['pred_maxlen'], test_acc))\n",
    "\n",
    "config['pred_maxlen'] = 20\n",
    "test_acc = getAccuracyScore(encoder, decoder, test_x, test_out, config['batch'], config['pred_maxlen']) * 100\n",
    "print('Accuracy on the test set (max prediction size = {}) = {:.2f}%'.format(config['pred_maxlen'], test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
