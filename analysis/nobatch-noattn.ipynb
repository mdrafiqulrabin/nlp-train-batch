{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import _pickle as pk\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing imports and config... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'patience': 10,\n",
    "    'batch': 32,\n",
    "    'epoch': 3000,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.99,\n",
    "    'emb_size': 64,\n",
    "    'lstm_size': 128,\n",
    "    'pred_size': 10,\n",
    "    'testfile': \"../data/raw/test.txt\",\n",
    "    'logfile': \"model_loop_noattn.log\",\n",
    "    'lossfile': 'model_loop_noattn.loss',\n",
    "    'checkpoint': \"model_loop_noattn.pt\"\n",
    "}\n",
    "\n",
    "open(config['logfile'], 'w').close()\n",
    "def saveLogMsg(msg):\n",
    "    print(msg, \"\\n\")\n",
    "    with open(config['logfile'], \"a\") as myfile:\n",
    "        myfile.write(msg + \"\\n\")\n",
    "        \n",
    "saveLogMsg(\"Initializing imports and config...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for train and valid... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(1, 3)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])\n",
    "\n",
    "saveLogMsg(\"Dataset for train and valid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab for source and target... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']\n",
    "\n",
    "saveLogMsg(\"Vocab for source and target...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dataset through Vocab... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Mapping dataset through Vocab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset from ../data/raw/test.txt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(config['testfile'], delimiter='\\t', header=None, usecols=[0,1])\n",
    "test_inp, test_out = test_data[0], test_data[1]  \n",
    "\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Loading test dataset from {}.\".format(config['testfile']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        x_tensor = [torch.tensor(sample).to(device) for sample in inputs]\n",
    "        x_pad = pad_sequence(x_tensor, batch_first=True, padding_value=0) # (batch, seqlen) \n",
    "        x_emb = self.emb(x_pad) # (batch, seqlen, emb_dim) \n",
    "        x_emb = self.drop(x_emb)\n",
    "        \n",
    "        x_len = [len(sample) for sample in inputs]\n",
    "        x_pack = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
    "        outs_pack, (h_n, c_n) = self.lstm(x_pack)\n",
    "        outs, _ = pad_packed_sequence(outs_pack, batch_first=True)\n",
    "        \n",
    "        if self.z_index == 1:\n",
    "            return h_n, c_n # (seqlen, batch, lstm_dim)\n",
    "        else:\n",
    "            return outs # (batch, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "saveLogMsg(\"encoder:\\n{}\".format(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder:\n",
      "Decoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (clf): Linear(in_features=128, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, dropout=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.clf = nn.Linear(lstm_size, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        \n",
    "    def forward(self, batch_state, batch_targets, curr_token_raw, last_token_raw):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        batch_state_h, batch_state_c = batch_state # (seqlen, batch, lstm_dim)\n",
    "        batch_state_ht = batch_state_h.transpose(0, 1) # (batch, seqlen, lstm_dim)\n",
    "        batch_state_ct = batch_state_c.transpose(0, 1) # (batch, seqlen, lstm_dim)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        for targets, state_h, state_c in zip(batch_targets, batch_state_ht, batch_state_ct):\n",
    "            curr_token, last_token = curr_token_raw, last_token_raw\n",
    "            state = (state_h, state_c)\n",
    "            shifted = targets + [last_token]\n",
    "            \n",
    "            each_loss = 0.0\n",
    "            for i in range(len(shifted)):\n",
    "                inp = torch.tensor([curr_token]).to(device)\n",
    "\n",
    "                emb = self.emb(inp)\n",
    "                emb = self.drop(emb)\n",
    "\n",
    "                state = self.lstm(emb, state)\n",
    "                q_i, _ = state \n",
    "                q_i = self.drop(q_i)\n",
    "        \n",
    "                scores = self.clf(q_i)\n",
    "                target = torch.tensor([shifted[i]]).to(device)\n",
    "                each_loss += self.objective(scores, target)\n",
    "\n",
    "                curr_token = shifted[i]\n",
    "            \n",
    "            batch_loss += (each_loss / len(shifted) * 1.0)\n",
    "            \n",
    "        return batch_loss\n",
    "\n",
    "    def predict(self, batch_state, curr_token_raw, last_token_raw, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        batch_state_h, batch_state_c = batch_state # (seqlen, batch, lstm_dim)\n",
    "        batch_state_ht = batch_state_h.transpose(0, 1) # (batch, seqlen, lstm_dim)\n",
    "        batch_state_ct = batch_state_c.transpose(0, 1) # (batch, seqlen, lstm_dim)\n",
    "        \n",
    "        batch_preds = []\n",
    "        for state_h, state_c in zip(batch_state_ht, batch_state_ct):\n",
    "            curr_token, last_token = curr_token_raw, last_token_raw\n",
    "            state = (state_h, state_c)\n",
    "            \n",
    "            each_preds = []\n",
    "            for i in range(maxlen):\n",
    "                inp = torch.tensor([curr_token]).to(device)\n",
    "                \n",
    "                emb = self.emb(inp)\n",
    "\n",
    "                state = self.lstm(emb, state)\n",
    "                h_i, _ = state\n",
    "\n",
    "                scores = self.clf(h_i)\n",
    "                pred = torch.argmax(torch.softmax(scores, dim=1))\n",
    "                curr_token = pred\n",
    "\n",
    "                if last_token == pred:\n",
    "                    break\n",
    "                each_preds.append(pred)\n",
    "                \n",
    "            batch_preds.append(each_preds)\n",
    "            \n",
    "        return batch_preds\n",
    "    \n",
    "    def evaluate(self, batch_state, batch_targets, curr_token_raw, last_token_raw):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        batch_state_h, batch_state_c = batch_state # (seqlen, batch, lstm_dim)\n",
    "        batch_state_ht = batch_state_h.transpose(0, 1) # (batch, seqlen, lstm_dim)\n",
    "        batch_state_ct = batch_state_c.transpose(0, 1) # (batch, seqlen, lstm_dim)\n",
    "        \n",
    "        batch_preds = []\n",
    "        batch_loss = 0.0\n",
    "        for state_h, state_c, targets in zip(batch_state_ht, batch_state_ct, batch_targets):\n",
    "            curr_token, last_token = curr_token_raw, last_token_raw\n",
    "            state = (state_h, state_c)\n",
    "            shifted = targets + [last_token]\n",
    "            \n",
    "            each_preds = []\n",
    "            each_loss = 0.0\n",
    "            for i in range(len(shifted)):\n",
    "                inp = torch.tensor([curr_token]).to(device)\n",
    "                \n",
    "                emb = self.emb(inp)\n",
    "\n",
    "                state = self.lstm(emb, state)\n",
    "                h_i, _ = state\n",
    "\n",
    "                scores = self.clf(h_i)\n",
    "                target = torch.tensor([shifted[i]]).to(device)\n",
    "                each_loss += self.objective(scores, target)\n",
    "                \n",
    "                pred = torch.argmax(torch.softmax(scores, dim=1))\n",
    "                curr_token = pred\n",
    "\n",
    "                if last_token == pred:\n",
    "                    break\n",
    "                each_preds.append(pred)\n",
    "                \n",
    "            batch_loss += (each_loss / len(each_preds) * 1.0)\n",
    "            batch_preds.append(each_preds)\n",
    "            \n",
    "        return batch_preds, batch_loss\n",
    "\n",
    "decoder = Decoder(vocab_size=len(tgt_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'])\n",
    "saveLogMsg(\"decoder:\\n{}\".format(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    batch_x = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds = decoder.predict(encoder(batch_x), START_IX, STOP_IX, pred_size)\n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_x = []\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample_loss = 0.0\n",
    "    batch_x, batch_y = [], []\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            batch_y.append(sample_y[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds, batch_loss = decoder.evaluate(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "                \n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_y = map_prediction(batch_y)\n",
    "                actuals.extend(batch_y)\n",
    "                \n",
    "                sample_loss += batch_loss.item()\n",
    "                batch_x, batch_y = [], []\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    batch_x, batch_y = [], []\n",
    "\n",
    "    for i in range(len(train_x)):\n",
    "        batch_x.append(train_x[i])\n",
    "        batch_y.append(train_y[i])\n",
    "\n",
    "        if len(batch_x) == batch_size or i == len(train_x) - 1:\n",
    "            batch_loss = decoder(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_x, batch_y = [], []\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, '', patience_track+1\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * ', 0\n",
    "\n",
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "    decoder = Decoder(vocab_size=len(tgt_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "def getCurrentTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out):\n",
    "    predictions = predict(encoder, decoder, sample_x, config['batch'], config['pred_size'])\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    patience_track = 0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.zero_grad(); enc_optim.zero_grad()\n",
    "        decoder.zero_grad(); dec_optim.zero_grad()\n",
    "        \n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track, patience_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track)\n",
    "        test_acc = getAccuracyScore(encoder, decoder, test_x, test_out)\n",
    "        \n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            epoch_msg = '[{}] Epoch {}:\\n [TRAIN] Loss: {:.6f}'.format(getCurrentTime(), epoch, train_loss)\n",
    "            epoch_msg += ' [DEV] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "            epoch_msg += ' [TEST] Acc: {:.6f}'.format(test_acc)\n",
    "            saveLogMsg(epoch_msg + epoch_track)\n",
    "            \n",
    "        if patience_track == int(config['patience']):\n",
    "            saveLogMsg('No accuracy improvment for {} consecutive epochs, stopping training...'.format(config['patience']))\n",
    "            break\n",
    "    \n",
    "    best_encoder, best_decoder, _ = load_best_model()\n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    return best_encoder, best_decoder, keep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with encoder and decoder... \n",
      "\n",
      "[2020-04-09 14:50:55.379515] Epoch 1:\n",
      " [TRAIN] Loss: 1.844442 [DEV] Loss: 1.485004, Acc: 0.275800 [TEST] Acc: 0.179200 *  \n",
      "\n",
      "[2020-04-09 14:53:02.161138] Epoch 2:\n",
      " [TRAIN] Loss: 0.725624 [DEV] Loss: 0.566061, Acc: 0.741200 [TEST] Acc: 0.595800 *  \n",
      "\n",
      "[2020-04-09 14:54:51.879143] Epoch 3:\n",
      " [TRAIN] Loss: 0.378644 [DEV] Loss: 0.213370, Acc: 0.904600 [TEST] Acc: 0.758400 *  \n",
      "\n",
      "[2020-04-09 14:57:13.084958] Epoch 4:\n",
      " [TRAIN] Loss: 0.213595 [DEV] Loss: 0.071513, Acc: 0.965200 [TEST] Acc: 0.853200 *  \n",
      "\n",
      "[2020-04-09 14:59:50.049918] Epoch 5:\n",
      " [TRAIN] Loss: 0.142425 [DEV] Loss: 0.038960, Acc: 0.982200 [TEST] Acc: 0.867000 *  \n",
      "\n",
      "[2020-04-09 15:02:27.214465] Epoch 6:\n",
      " [TRAIN] Loss: 0.099749 [DEV] Loss: 0.037703, Acc: 0.984200 [TEST] Acc: 0.874600 *  \n",
      "\n",
      "[2020-04-09 15:04:51.297170] Epoch 7:\n",
      " [TRAIN] Loss: 0.079309 [DEV] Loss: 0.019547, Acc: 0.990800 [TEST] Acc: 0.896800 *  \n",
      "\n",
      "[2020-04-09 15:07:44.974085] Epoch 8:\n",
      " [TRAIN] Loss: 0.068503 [DEV] Loss: 0.036061, Acc: 0.987600 [TEST] Acc: 0.881400 \n",
      "\n",
      "[2020-04-09 15:11:18.224310] Epoch 9:\n",
      " [TRAIN] Loss: 0.059796 [DEV] Loss: 0.018907, Acc: 0.991600 [TEST] Acc: 0.896400 *  \n",
      "\n",
      "[2020-04-09 15:14:22.216215] Epoch 10:\n",
      " [TRAIN] Loss: 0.052725 [DEV] Loss: 0.022814, Acc: 0.991000 [TEST] Acc: 0.901800 \n",
      "\n",
      "[2020-04-09 15:17:57.064914] Epoch 11:\n",
      " [TRAIN] Loss: 0.043876 [DEV] Loss: 0.017002, Acc: 0.992400 [TEST] Acc: 0.903600 *  \n",
      "\n",
      "[2020-04-09 15:21:33.658053] Epoch 12:\n",
      " [TRAIN] Loss: 0.040587 [DEV] Loss: 0.009461, Acc: 0.995800 [TEST] Acc: 0.911800 *  \n",
      "\n",
      "[2020-04-09 15:26:25.065379] Epoch 13:\n",
      " [TRAIN] Loss: 0.045954 [DEV] Loss: 0.013554, Acc: 0.994600 [TEST] Acc: 0.905600 \n",
      "\n",
      "[2020-04-09 15:30:47.396598] Epoch 14:\n",
      " [TRAIN] Loss: 0.043888 [DEV] Loss: 0.009532, Acc: 0.995800 [TEST] Acc: 0.912400 \n",
      "\n",
      "[2020-04-09 15:35:28.130062] Epoch 15:\n",
      " [TRAIN] Loss: 0.038539 [DEV] Loss: 0.009627, Acc: 0.996000 [TEST] Acc: 0.913000 *  \n",
      "\n",
      "[2020-04-09 15:37:56.408233] Epoch 16:\n",
      " [TRAIN] Loss: 0.030844 [DEV] Loss: 0.008944, Acc: 0.995800 [TEST] Acc: 0.917200 \n",
      "\n",
      "[2020-04-09 15:40:24.006027] Epoch 17:\n",
      " [TRAIN] Loss: 0.033330 [DEV] Loss: 0.007047, Acc: 0.996400 [TEST] Acc: 0.914600 *  \n",
      "\n",
      "[2020-04-09 15:42:20.137306] Epoch 18:\n",
      " [TRAIN] Loss: 0.032098 [DEV] Loss: 0.007199, Acc: 0.996600 [TEST] Acc: 0.912600 *  \n",
      "\n",
      "[2020-04-09 15:44:09.625299] Epoch 19:\n",
      " [TRAIN] Loss: 0.032012 [DEV] Loss: 0.005814, Acc: 0.997200 [TEST] Acc: 0.916800 *  \n",
      "\n",
      "[2020-04-09 15:45:59.120401] Epoch 20:\n",
      " [TRAIN] Loss: 0.031263 [DEV] Loss: 0.006209, Acc: 0.996800 [TEST] Acc: 0.915400 \n",
      "\n",
      "[2020-04-09 15:47:48.537800] Epoch 21:\n",
      " [TRAIN] Loss: 0.029391 [DEV] Loss: 0.010409, Acc: 0.995800 [TEST] Acc: 0.917400 \n",
      "\n",
      "[2020-04-09 15:49:37.991163] Epoch 22:\n",
      " [TRAIN] Loss: 0.029328 [DEV] Loss: 0.007088, Acc: 0.997800 [TEST] Acc: 0.918400 *  \n",
      "\n",
      "[2020-04-09 15:51:27.492265] Epoch 23:\n",
      " [TRAIN] Loss: 0.026238 [DEV] Loss: 0.014339, Acc: 0.995600 [TEST] Acc: 0.916600 \n",
      "\n",
      "[2020-04-09 15:53:16.991483] Epoch 24:\n",
      " [TRAIN] Loss: 0.026828 [DEV] Loss: 0.011082, Acc: 0.996200 [TEST] Acc: 0.918000 \n",
      "\n",
      "[2020-04-09 15:55:06.684080] Epoch 25:\n",
      " [TRAIN] Loss: 0.026350 [DEV] Loss: 0.005692, Acc: 0.997200 [TEST] Acc: 0.918200 \n",
      "\n",
      "[2020-04-09 15:56:56.422100] Epoch 26:\n",
      " [TRAIN] Loss: 0.028726 [DEV] Loss: 0.029375, Acc: 0.994800 [TEST] Acc: 0.914000 \n",
      "\n",
      "[2020-04-09 15:58:46.164872] Epoch 27:\n",
      " [TRAIN] Loss: 0.025519 [DEV] Loss: 0.007524, Acc: 0.997400 [TEST] Acc: 0.916000 \n",
      "\n",
      "[2020-04-09 16:01:28.441813] Epoch 28:\n",
      " [TRAIN] Loss: 0.024239 [DEV] Loss: 0.009593, Acc: 0.996200 [TEST] Acc: 0.914400 \n",
      "\n",
      "[2020-04-09 16:06:32.181228] Epoch 29:\n",
      " [TRAIN] Loss: 0.021670 [DEV] Loss: 0.006797, Acc: 0.997200 [TEST] Acc: 0.919000 \n",
      "\n",
      "[2020-04-09 16:11:46.877356] Epoch 30:\n",
      " [TRAIN] Loss: 0.024913 [DEV] Loss: 0.005351, Acc: 0.997200 [TEST] Acc: 0.919000 \n",
      "\n",
      "[2020-04-09 16:16:50.062877] Epoch 31:\n",
      " [TRAIN] Loss: 0.023364 [DEV] Loss: 0.008263, Acc: 0.996200 [TEST] Acc: 0.917600 \n",
      "\n",
      "[2020-04-09 16:21:55.968457] Epoch 32:\n",
      " [TRAIN] Loss: 0.028131 [DEV] Loss: 0.017069, Acc: 0.995000 [TEST] Acc: 0.910800 \n",
      "\n",
      "No accuracy improvment for 10 consecutive epochs, stopping training... \n",
      "\n",
      "Training done... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True: #not os.path.exists(config['checkpoint']):\n",
    "    saveLogMsg(\"Training with encoder and decoder...\")\n",
    "    training_loop(encoder, decoder, train_x, train_y, config['epoch'], config['batch'], print_every=1)\n",
    "    saveLogMsg('Training done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning best model from epoch 22 with loss 0.007088 and accuracy 0.997800. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "encoder, decoder, state = load_best_model()\n",
    "saveLogMsg('Returning best model from epoch {} with loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training and validation loss... \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXhU5dn48e+dyUYWSCBBEtag1LKFgCnSooKBWtC61ldRXFur9dVaa/V1aeve1tftxX1rte5KqSj9SV1Q1oqVpYgItCK7CZAACdkg2/3745wJkzCTTJbJJJn7c13nmrOf+8wkc8/znHOeR1QVY4wxprGocAdgjDGmc7IEYYwxxi9LEMYYY/yyBGGMMcYvSxDGGGP8sgRhjDHGL0sQEUJE7hSRV8Idh5eIzBSRD9p73XAK1XssIn8WkXvd8RNF5N/BrNvKY5WJyNDWbt/EfreKyNT23q8JLUsQ3YT7j+0d6kSk0md6Zjsfq01fQgCq+qqqntLe63Z3qrpUVY9tj32JyCIRuaLR/pNUdXN77N90fZYgugn3HztJVZOA7cDpPvNe7chYRCS6I49njAkNSxCRJVZEXhKRUhH5UkRyvQtEJFNE/ioihSKyRUSu87cDEbkSmAn8j1s6+Zs7f6uI3Cwia4FyEYkWkVtE5Gv3eOtF5Gyf/VwmIst8plVEfiYiX4nIfhF5QkSkFet6ROQhESlyz+Nad32/SSuYGEXkQfc4W0Rkus/yLBFZ7G77IZAW6I0XkQ0i8kOf6Wg3xnHu9F9EZJeIlIjIEhEZGWA/k0Vkp8/0WBFZ7cbwJhDvsyxVRP6f+5nud8cHuMt+B5wIPO5+jo/7vLfHuOO93L+XQhHZJiK/EZGoYN6bpohInIjMEpF8d5glInHusjQ3zmIR2SciS32OebOIfOOe679FZIo7P8rnc9wrIrNFpLe7LF5EXnHnF4vIChE5Kpg4jSWISHMG8AaQAswDvF8KUcDfgM+B/sAU4HoR+UHjHajqs8CrwP1u6eR0n8UXAKcBKapaA3yN8yXUC7gLeEVEMpqI74fAd4AxwHnAEccPYt2fAtOBHGAccFYT+yCIGI8H/o3z5X8/8CdvMgJeA1a5y+4BLm3iOK/jvD9ePwCKVHW1O/13YBjQF1iN8x43SURigbeBl4HewF+AH/msEgW8AAwGBgGVuJ+5qv4aWApc636O1/o5xGM478tQYBJwCXC5z/Km3pum/BqYgPMZjQHGA79xl/0K2AmkA0cBtwEqIscC1wLfUdVknPdvq7vNdTif8yQgE9gPPOEuu9Q9h4FAH+Bn7vtggqGqNnSzAecfZ2qjeXcCC3ymRwCV7vjxwPZG698KvBBg/38G7vVzzB83E9ca4Ex3/DJgmc8yBU7wmZ4N3NKKdT8GrvJZNtVdPzrI965xjJt8liW4++qH84VbAyT6LH8NeCXAfo8BSoEEd/pV4PYA66a4x+nV+P0GJgM73fGTgHxAfLb9pPFn47MsB9jvM70IuKLROurG6gEOASN8ll0FLGruvWnubxInKZ/qs+wHwFZ3/G7gHeAYP+/fHvfzjGm0bAMwxWc6A6gGooEfu+9Jdkf/H3aHwUoQkWWXz3gFEO9WvQwGMt0ieLGIFOP8cmtpUXyH74SIXCIia3z2OYomqmH8xJfUinUzG8XRIKbGgoix/jiqWuGOJrnH2a+q5T7rbgt0HFXdhPNFdrqIJOCU5l5zY/CIyH1uFckBDv8ybuq9wo3hG3W/FRvHICIJIvKMWz10AFgCpIiIp5n9eo8d2+ictuGUML0CvTfNyfSz30x3/AFgE/CBiGwWkVvc/W8Crsf5obNHRN4QEe82g4G5Pp/hBqAW5+/3ZeB94A23Out+EYkJIkaDVTEZxw5gi6qm+AzJqnpqgPUDNQFcP19EBgPP4VQL9FHVFGAdEEwVRFsUAAN8pgcGWrGNMRYAqSKS6DNvUDPbeKuZzgTWu196ABe686biVIcM8YYYRAz9G1Xr+MbwK+BY4HhV7YlT4vDdb1NNORfh/Aof3Gjf3zQTUzDy/ew3H0BVS1X1V6o6FDgduMF7rUFVX1PVE9xtFfhfd/sdwPRGf7/xqvqNqlar6l2qOgL4Hk7V5CXtcA4RwRKEAfgMOOBeBOzh/qIdJSLfCbD+bpx66aYk4vwTFwKIyOU4v85DbTbwCxHpLyIpwM1NrNvqGFV1G7ASuEtEYkXkBJwvtKa8AZwCXI1benAl41Tn7MWpqvl9MDEAy3Gqua5zL3qfg1Of77vfSqDYvWh7R6PtA36OqlqL817+TkSS3WR6A9Aez3m8DvxGRNJFJA243btfEfmhiBzjJr0DOCWBWhE5VkTy3IvZB93zqnX397Qb52B3H+kicqY7frKIjHZLTQdwkl4tJiiWIIz3y+B0nDrqLTi/Hv+I82vWnz8BI9wi/dsB9rkeeAjnS2w3MBr4RzuH7s9zwAfAWuBfwHycL9EjvhTaIcYLca7f7MP58n2pqZVVtcA91veAN30WvYRTzfINsB74NJiDq2oVcA7O9YD9wPnAWz6rzAJ64HyenwLvNdrFI8C57l1Ij/o5xM+BcmAzsAwnqT0fTGzNuBcnua4FvsC5KO99rmYYsAAow3mvnlTVRUAccJ97LrtwLubf5nMe83CqpUpxzvV4d1k/YA5OctgALOZwMnpaRJ5uh/PptqRh9aUx3Yt76+XTqjq42ZWNMQ1YCcJ0K24V2alulUt/nF/2c8MdlzFdkZUgTLfi3iG0GPg2Tj31u8AvVPVAWAMzpguyBGGMMcYvq2IyxhjjV7dqVC0tLU2HDBkS7jCMMabLWLVqVZGqpvtb1q0SxJAhQ1i5cmW4wzDGmC5DRAK2AGBVTMYYY/yyBGGMMcYvSxDGGGP86lbXIIwxHa+6upqdO3dy8ODBcIdimhAfH8+AAQOIiQm+MVtLEMaYNtm5cyfJyckMGTKE4PoLMh1NVdm7dy87d+4kKysr6O2siskY0yYHDx6kT58+lhw6MRGhT58+LS7lWYIwxrSZJYfOrzWfUcQnCFW49154//1wR2KMMZ1LxCcIEXjgAZg/P9yRGGNaqri4mCeffLJV25566qkUFxc3uc7tt9/OggULWrX/xoYMGUJRUVG77KujRHyCAEhPh8LCcEdhjGmpphJEbW3THcfNnz+flJSUJte5++67mTp1aqvj6+osQWAJwpiu6pZbbuHrr78mJyeHm266iUWLFnHyySdz4YUXMnr0aADOOussjjvuOEaOHMmzzz5bv633F/3WrVsZPnw4P/3pTxk5ciSnnHIKlZWVAFx22WXMmTOnfv077riDcePGMXr0aDZu3AhAYWEh3//+9xk3bhxXXXUVgwcPbrak8PDDDzNq1ChGjRrFrFmzACgvL+e0005jzJgxjBo1ijfffLP+HEeMGEF2djY33nhj+76BzbDbXIG0NNixI9xRGNP1XX89rFnTvvvMyQH3O/QI9913H+vWrWONe9BFixbx2WefsW7duvrbOZ9//nl69+5NZWUl3/nOd/jRj35Enz59Guznq6++4vXXX+e5557jvPPO469//SsXXXTREcdLS0tj9erVPPnkkzz44IP88Y9/5K677iIvL49bb72V9957r0ES8mfVqlW88MIL/POf/0RVOf7445k0aRKbN28mMzOTd999F4CSkhL27dvH3Llz2bhxIyLSbJVYe7MSBFaCMKY7GT9+fIN7/R999FHGjBnDhAkT2LFjB1999dUR22RlZZGTkwPAcccdx9atW/3u+5xzzjlinWXLljFjxgwApk2bRmpqapPxLVu2jLPPPpvExESSkpI455xzWLp0KaNHj2bBggXcfPPNLF26lF69etGzZ0/i4+O54ooreOutt0hISGjp29EmVoLgcIJQdS5aG2NaJ9Av/Y6UmJhYP75o0SIWLFjA8uXLSUhIYPLkyX6fBYiLi6sf93g89VVMgdbzeDzU1NQAzkNoLRFo/W9961usWrWK+fPnc+utt3LKKadw++2389lnn/HRRx/xxhtv8Pjjj/Pxxx+36HhtYSUInARRXQ0HrFNKY7qU5ORkSktLAy4vKSkhNTWVhIQENm7cyKefftruMZxwwgnMnj0bgA8++ID9+/c3uf5JJ53E22+/TUVFBeXl5cydO5cTTzyR/Px8EhISuOiii7jxxhtZvXo1ZWVllJSUcOqppzJr1qz6qrSOErIShIg8D/wQ2KOqo/wsvwmY6RPHcCBdVfeJyFagFKgFalQ1N1RxgpMgAIqKoFevUB7JGNOe+vTpw8SJExk1ahTTp0/ntNNOa7B82rRpPP3002RnZ3PssccyYcKEdo/hjjvu4IILLuDNN99k0qRJZGRkkJycHHD9cePGcdlllzF+/HgArrjiCsaOHcv777/PTTfdRFRUFDExMTz11FOUlpZy5plncvDgQVSV//u//2v3+JsSsj6pReQkoAx4yV+CaLTu6cAvVTXPnd4K5Kpqi24azs3N1dZ0GDR/Ppx2GixfDiH4+zGmW9uwYQPDhw8Pdxhhc+jQITweD9HR0Sxfvpyrr766w3/pB8vfZyUiqwL9CA9ZCUJVl4jIkCBXvwB4PVSxNMdbgrAL1caYltq+fTvnnXcedXV1xMbG8txzz4U7pHYT9ovUIpIATAOu9ZmtwAciosAzqhrwvjERuRK4EmDQoEGtisEShDGmtYYNG8a//vWvcIcREp3hIvXpwD9UdZ/PvImqOg6YDlzjVlf5parPqmququamp/vtd7tZliCMMeZInSFBzKBR9ZKq5ruve4C5wPhQBpCYCD16WIIwxhhfYU0QItILmAS84zMvUUSSvePAKcC6UMeSlmYJwhhjfIXyNtfXgclAmojsBO4AYgBU9Wl3tbOBD1S13GfTo4C5btvl0cBrqvpeqOL0sqepjTGmoZCVIFT1AlXNUNUYVR2gqn9S1ad9kgOq+mdVndFou82qOsYdRqrq70IVoy9LEMZEhqSkJADy8/M599xz/a4zefJkmrtlftasWVRUVNRPB9N8eDDuvPNOHnzwwTbvpz10hmsQnYIlCGMiS2ZmZn1Lra3ROEEE03x4V2MJwpWe7jxJbYzpOm6++eYG/UHceeedPPTQQ5SVlTFlypT6prnfeeedI7bdunUro0Y5z/BWVlYyY8YMsrOzOf/88xu0xXT11VeTm5vLyJEjueOOOwCnAcD8/HxOPvlkTj75ZKBhh0D+mvNuqlnxQNasWcOECRPIzs7m7LPPrm/G49FHH61vAtzbUODixYvJyckhJyeHsWPHNtkESbDC/hxEZ5GeDuXlUFnp3NFkjGm569+7njW72vcp4px+Ocya5r8VwBkzZnD99dfz3//93wDMnj2b9957j/j4eObOnUvPnj0pKipiwoQJnHHGGQH7ZX7qqadISEhg7dq1rF27lnHjxtUv+93vfkfv3r2pra1lypQprF27luuuu46HH36YhQsXkpaW1mBfgZrzTk1NDbpZca9LLrmExx57jEmTJnH77bdz1113MWvWLO677z62bNlCXFxcfbXWgw8+yBNPPMHEiRMpKysjPj6+Re+zP1aCcNmzEMZ0PWPHjmXPnj3k5+fz+eefk5qayqBBg1BVbrvtNrKzs5k6dSrffPMNu3fvDrifJUuW1H9RZ2dnk52dXb9s9uzZjBs3jrFjx/Lll1+yfv36JmMK1Jw3BN+sODgNDRYXFzNp0iQALr30UpYsWVIf48yZM3nllVeIjnZ+50+cOJEbbriBRx99lOLi4vr5bWElCJdvgmjlA9nGRLxAv/RD6dxzz2XOnDns2rWrvrrl1VdfpbCwkFWrVhETE8OQIUP8NvPty1/pYsuWLTz44IOsWLGC1NRULrvssmb301T7dsE2K96cd999lyVLljBv3jzuuecevvzyS2655RZOO+005s+fz4QJE1iwYAHf/va3W7V/LytBuKwEYUzXNGPGDN544w3mzJlTf1dSSUkJffv2JSYmhoULF7Jt27Ym93HSSSfx6quvArBu3TrWrl0LwIEDB0hMTKRXr17s3r2bv//97/XbBGpqPFBz3i3Vq1cvUlNT60sfL7/8MpMmTaKuro4dO3Zw8sknc//991NcXExZWRlff/01o0eP5uabbyY3N7e+S9S2sBKEyxKEMV3TyJEjKS0tpX///mRkZAAwc+ZMTj/9dHJzc8nJyWn2l/TVV1/N5ZdfTnZ2Njk5OfVNcY8ZM4axY8cycuRIhg4dysSJE+u3ufLKK5k+fToZGRksXLiwfn6g5rybqk4K5MUXX+RnP/sZFRUVDB06lBdeeIHa2louuugiSkpKUFV++ctfkpKSwm9/+1sWLlyIx+NhxIgRTJ8+vcXHayxkzX2HQ2ub+wbYvx9694aHHoIbbmjnwIzpxiK9ue+upKXNfVsVkyslBaKjrQRhjDFeliBcItYekzHG+LIE4cOepjamdbpTVXV31ZrPyBKED3ua2piWi4+PZ+/evZYkOjFVZe/evS1+eM7uYvKRng6rV4c7CmO6lgEDBrBz504KrfjdqcXHxzNgwIAWbWMJwodVMRnTcjExMWRlZYU7DBMCVsXkIz0diouhujrckRhjTPhZgvDhfVjOrkMYY4wliAbsaWpjjDnMEoQPb6u9liCMMSaECUJEnheRPSKyLsDyySJSIiJr3OF2n2XTROTfIrJJRG4JVYyNWQnCGGMOC2UJ4s/AtGbWWaqqOe5wN4CIeIAngOnACOACERkRwjjrWYIwxpjDQpYgVHUJsK8Vm44HNqnqZlWtAt4AzmzX4ALo08dpcsMuUhtjTPivQXxXRD4Xkb+LyEh3Xn9gh886O915fonIlSKyUkRWtvVBHY/HadHVShDGGBPeBLEaGKyqY4DHgLfd+f46jQ34DL+qPququaqam+6tI2oBVWXEEyP4w9I/APawnDHGeIUtQajqAVUtc8fnAzEikoZTYhjos+oAID9UcYgI+w/uZ/P+zYAlCGOM8QpbghCRfuJ2Aisi491Y9gIrgGEikiUiscAMYF4oY8lMziS/zMlBliCMMcYRsraYROR1YDKQJiI7gTuAGABVfRo4F7haRGqASmCGOs1B1ojItcD7gAd4XlW/DFWcABlJGeSXHk4QbhewxhgT0UKWIFT1gmaWPw48HmDZfGB+KOLyJyMpg5X5Tlel6emwdy/U1UFUuC/hG2NMGNlXIE4V057yPdTU1ZCW5iSHfa25QdcYY7oRSxBARnIGirK7bLc9LGeMMS5LEDglCICCsgJLEMYY47IEgXMNAiC/NN+a/DbGGJclCHxKEKVWgjDGGC9LEMBRSUchCAVlBdbktzHGuCxBANFR0fRN7Et+aT5xcdCzpyUIY4yxBOHKSM6goKwAsKepjTEGLEHUa/w0tSUIY0ykswThykzOpKDUShDGGONlCcKVkZTB7vLd1NbVkpZmCcIYYyxBuDKTM6nTOvaU76kvQWjAXiiMMab7azZBiEiiiES5498SkTNEJCb0oXWsjOSGD8tVV0NpaZiDMsaYMAqmBLEEiBeR/sBHwOXAn0MZVDhYcxvGGNNQMAlCVLUCOAd4TFXPBkaENqyO56+5DUsQxphIFlSCEJHvAjOBd915IetHIlz6JfUDrLkNY4zxCiZBXA/cCsxV1S9FZCiwMLRhdbwYTwzpCelWxWSMMa5mSwKquhhYDOBerC5S1etCHVg4ZCRnWBWTMca4grmL6TUR6SkiicB64N8iclMQ2z0vIntEZF2A5TNFZK07fCIiY3yWbRWRL0RkjYisbMkJtUVmciYFZQUkJkKPHpYgjDGRLZgqphGqegA4C6ef6EHAxUFs92dgWhPLtwCTVDUbuAd4ttHyk1U1R1VzgzhWu7DmNowx5rBgEkSM+9zDWcA7qloNNPsImaouAQL27Kyqn6jqfnfyU2BAELGEVGZyJrvL7GlqY4yB4BLEM8BWIBFYIiKDgQPtHMdPgL/7TCvwgYisEpErm9pQRK4UkZUisrKwjd/oGUkZ1GothRWFVoIwxkS8ZhOEqj6qqv1V9VR1bANObq8ARORknARxs8/siao6DpgOXCMiJzUR37Oqmququeneq8ut1LhnOet21BgTyYK5SN1LRB72/koXkYdwShNtJiLZwB+BM1V1r3e+qua7r3uAucD49jhecxo3t2ElCGNMJAumiul5oBQ4zx0OAC+09cAiMgh4C7hYVf/jMz9RRJK948ApgN87odpb4+Y2ysuhsrIjjmyMMZ1PME9EH62qP/KZvktE1jS3kYi8DkwG0kRkJ3AHEAOgqk8DtwN9gCdFBKDGvWPpKGCuOy8aeE1V3wv6jNrA92nqDJ9nIQYN6oijG2NM5xJMgqgUkRNUdRmAiEwEmv1draoXNLP8CuAKP/M3A2OO3CL0Yj2x9OnRh/zSfLItQRhjIlwwCeJq4EUR6QUIzq2rl4UyqHDyPiyX7iYFuw5hjIlUwTS1sQYYIyI93en2vsW1U7HmNowxxhEwQYjIDQHmA6CqD4coprDKTM5kfeF6SxDGmIjXVAkiucOi6EQykjLYVbaL5J51REdHWYIwxkSsgAlCVe/qyEA6i8zkTGrqathbWURaWl97WM4YE7GCeQ4iojTuWc5KEMaYSGUJopHGzW1YgjDGRKpgmtrwdEQgnYW3uQ3v09SWIIwxkSqYEsQmEXlAREaEPJpOwPs0tVUxGWMiXTAJIhv4D/BHEfnUbV67Z4jjCpv46Hh69+hdX8VUXAzV1eGOyhhjOl4wzX2Xqupzqvo94H9w2lQqEJEXReSYkEcYBhlJGeSXHX5Yzu5kMsZEoqCuQYjIGSIyF3gEeAgYCvwNpwvSbiczObO+BAFWzWSMiUzBtMX0FbAQeEBVP/GZP6epjny6sozkDDYWbSR9mDNtCcIYE4mCSRDZqlrmb4GqXtfO8XQKmUmZ7CrbRe8+dYA9TW2MiUzBXKTuKyJ/E5EiEdkjIu+IyNCQRxZGGckZVNdV40l2OrmzaxDGmEgUTIJ4DZgN9AMygb8Ar4cyqHDzPix3KKYAEatiMsZEpmAShKjqy6pa4w6vABrqwMLJ29zG7op8eve2BGGMiUzBXINYKCK3AG/gJIbzgXdFpDeAqu4LYXxhUf80tTW3YYyJYMGUIM4HrsK5k2kRTg9zPwZWASub2lBEnnevW6wLsFxE5FER2SQia0VknM+yS0XkK3e4NMjzaRfeEoQ1t2GMiWTB9CiX1Yb9/xl4HHgpwPLpwDB3OB54CjjeLZ3cAeTilFpWicg8Vd3fhliC1iOmBynxKfXNbWzc2BFHNcaYziWYB+ViROQ6EZnjDteKSEwwO1fVJTh9WAdyJvCSOj4FUkQkA/gB8KGq7nOTwofAtGCO2V7q+6a2EoQxJkIFU8X0FHAc8KQ7HOfOaw/9gR0+0zvdeYHmH8FtG2qliKwsbMdv8oykw31T790LdXXttmtjjOkSgrlI/R1VHeMz/bGIfN5Oxxc/87SJ+UfOVH0WeBYgNze33e6uykzOZMm2JaSnO8lh3z5IS2uvvRtjTOcXTAmiVkSO9k64D8nVttPxdwIDfaYHAPlNzO8wGUkZFJQVkJbm5Bx7WM4YE2mCSRA34dzqukhEFgMfA79qp+PPAy5x72aaAJSoagHwPnCKiKSKSCpwijuvw2QkZ1BVW0VcinMJxa5DGGMiTZNVTCISBVTi3GV0LE7Vz0ZVPRTMzkXkdWAykCYiO3HuTIoBUNWncVqDPRXYBFQAl7vL9onIPcAKd1d3d/TzFt6nqeuS8oE+liCMMRGnyQShqnUi8pCqfhdY29Kdq+oFzSxX4JoAy54Hnm/pMduL91mI6rgCYLQlCGNMxAmmiukDEfmRiPi7cNxteUsQFZ4CwKqYjDGRJ5i7mG4AEoEaETmIU82kqtptux2Fw81tFFbm07OnJQhjTOQJ5knq5I4IpLNJiEmgV1wve1jOGBOxgnmS+qNg5nVHGcmHH5azBGGMiTQBSxAiEg8k4NyBlMrhh9d64vQL0e35NrexfXu4ozHGmI7VVAniKpwWW7/tvnqHd4AnQh9a+Pk2t2ElCGNMpAlYglDVR4BHROTnqvpYB8bUaWQkZVBQWkBaulJUJKhCZN3LZYyJZMFcpH5MRL4HDPFdX1UDNeHdbWQmZ3Ko9hCJffZTVdWb0lLo2a3v3TLGmMOaTRAi8jJwNLCGw20wKYH7eOg2vLe6RqcUAL0pLLQEYYyJHME8B5ELjHCfeo4o3oflNKkAGElhIRx9dNPbGGNMdxHMk9TrgH6hDqQzqm9uI95pSNYuVBtjIkkwJYg0YL2IfAbUN9KnqmeELKpOwlvFdDDamtswxkSeYBLEnaEOorNKik0iOTaZA1gJwhgTeYK5i2mxiAwGhqnqAhFJADyhD61zyEzOpOhgAT16WIIwxkSWYJra+CkwB3jGndUfeDuUQXUm1tyGMSZSBXOR+hpgInAAQFW/AvqGMqjOxNv1aHq6dTtqjIkswSSIQ6pa5Z0QkWic5yAiQmZyJvml+aSlq5UgjDERJZgEsVhEbgN6iMj3gb8AfwttWJ1HRlIGB2sO0qtviSUIY0xECSZB3AIUAl/gNOA3H/hNMDsXkWki8m8R2SQit/hZ/n8issYd/iMixT7Lan2WzQvudNqf92G5+PR8SxDGmIgSzF1MdcBzwHMiMk5VVwezYxHx4LT6+n1gJ7BCROap6nqfff/SZ/2fA2N9dlGpqjnBnUbo1De3kVpAefkIKiuhR48wB2WMMR0gmBKErz+2YN3xwCZV3exew3gDOLOJ9S8AXm9hPCHnLUFIsj0sZ4yJLC1NEC1p7Lo/sMNneqc778idOs9ZZAEf+8yOF5GVIvKpiJwVMCCRK931VhaG4NvbmtswxkSqliaIu1qwrr9kEujupxnAHFWt9Zk3SFVzgQuBWSLit5k8VX1WVXNVNTc9Pb0F4QUnOS6ZpNgkDsZYCcIYE1mCeVBuoogkupNJIvKw+4u/OTuBgT7TA8Bts+JIM2hUvaSq+e7rZmARDa9PdKiMpAzKxAnduh41xkSKYEoQTwEVIjIGuAnYRnB9QawAholIlojE4iSBI+5GEpFjgVRguc+8VBGJc8fTcB7UW994246SkZxBqRbQrx8sWhSuKIwxpmMFkyBq3L4gzgQedbsiTW5uI9psupkAABt/SURBVFWtAa4F3gc2ALNV9UsRuVtEfFuCvQB4o1F/E8OBlSLyObAQuM/37qeO5n1YbsoU+OgjiLyeMYwxkSiY1lxLReRW4CLgJPf21Zhgdq6q83Gem/Cdd3uj6Tv9bPcJMDqYY3QEb3MbeXnKq68K69bB6E4TnTHGhEYwJYjzcfqB+Imq7sK5E+mBkEbVyWQmZ1JRXcH4kw4ATinCGGO6u2ASRCnwiKouFZFvATl0wucVQsl7q2t0SgHDhsGCBWEOyBhjOkAwCWIJECci/YGPgMuBP4cyqM7G+7BcQWkBU6fC4sVQXR3moIwxJsSCSRCiqhXAOcBjqno2MDK0YXUu3uY2vBeqy8pgxYowB2WMMSEWVIIQke8CM4F33XkR06Mc+JQgygo4+WQQsWomY0z3F0yCuB64FZjr3qY6FOfW04iRHJtMQkwC+aX59O4N48bZhWpjTPfXbIJQ1cWqegbwpIgkuY3vXdcBsXUaIlJ/qyvAlCmwfDmUl4c5MGOMCaFgmtoYLSL/AtYB60VklYhE1DUIOPywHMDUqc5F6qVLwxyUMcaEUDBVTM8AN6jqYFUdBPwKp3+IiJKRnEFBqVOCmDgRYmPtOoQxpnsLJkEkqmr9NQdVXQQkBl69e8pMOlyCSEiA733PrkMYY7q3YBLEZhH5rYgMcYffAFtCHVhnk5GcQXl1OaWHSgGnmmnNGigqCnNgxhgTIsEkiB8D6cBb7pCG87BcRPG91RWcC9UAH38caAtjjOnamkwQbsN8t6nqdao6zh2uV9X9HRRfp+FtbsNbzZSbCz17WjWTMab7ajJBuD28HddBsXRq/Xs6vaVuK94GQHQ0TJ5sF6qNMd1XMFVM/xKReSJysYic4x1CHlknM6z3MFLiU1i2fVn9vClTYPNm2Lo1fHEZY0yoBJMgegN7gTzgdHf4YSiD6ow8UR4mD5nMx1sPX3SYOtV5tWomY0x31GyHQaoacRekA8kbksfbG99ma/FWhqQMYfhwyMhwqpl+8pNwR2eMMe0rmCepXxSRFJ/pVBF5PrRhdU55WXkAfLzFKUWIQF6eU4KoqwtnZMYY0/6CqWLKVtVi74R7B9PYYHYuItNE5N8isklEbvGz/DIRKRSRNe5whc+yS0XkK3e4NJjjhdqI9BEclXhUfYIAp5qpsBDWrQtjYMYYEwLB9EkdJSKp3ltbRaR3MNu5t8g+AXwf2AmsEJF5qrq+0apvquq1jbbtDdwB5AIKrHK3DevttSJCXlYeH2/5GFVFROqfh/joI8jODmd0xhjTvoIpQTwEfCIi94jI3cAnwP1BbDce2OS2/loFvAGcGWRcPwA+VNV9blL4EJgW5LYhlZeVR0FZARuLNgIwcCB861t2u6sxpvsJprnvl4AfAbuBQuAcVX05iH33B3b4TO905zX2IxFZKyJzRGRgC7dFRK4UkZUisrKwsDCIsNqm8XUIcG53XbLEuiE1xnQvwZQgUNX1qvq4qj7mp4ooEPG3q0bTfwOGqGo2sAB4sQXbemN7VlVzVTU3PT09yNBab2jqUIakDGlwu6u3G9LPPgv54Y0xpsMElSBaaScw0Gd6AJDvu4Kq7lXVQ+7kcxx+arvZbcMpb0geC7cspLauFsC6ITXGdEuhTBArgGEikiUiscAMYJ7vCiKS4TN5BrDBHX8fOMW9pTYVOMWd1ynkZeWx/+B+Pt/9OYB1Q2qM6ZZCliBUtQa4FueLfQMw2+3T+m4ROcNd7ToR+VJEPgeuAy5zt90H3IOTZFYAd7vzOoVA1yGWL3eqmowxpjsQVb9V+11Sbm6urly5skOONeKJEQxJGcL8mfMB+PBDOOUUmD8fpk/vkBCMMabNRGSVqub6WxbKKqZuLS8rjyXbllBVWwUc7obUqpmMMd2FJYhWysvKo7y6nBXfrACcbkgnTrQL1caY7sMSRCtNHjIZQY64DvH5507TG8YY09VZgmil3j16MzZjLB9tOVynZN2QGmO6E0sQbZA3JI/lO5dTUV0BWDekxpjuxRJEG0wZOoWq2io+2fEJYN2QGmO6F0sQbXDCoBOIjormo82HiwxTp8KWLbA+2AZJjDGmk7IE0QZJsUkc3//4Bu0ynXceJCXBb34TxsCMMaYdWIJoo7ysPFbmr6TkYAkARx0FN98Mc+fCsmVhDs4YY9rAEkQbTcmaQp3WsWTbkvp5N9wAmZnwq19BN3pQ3RgTYSxBtNGEAROIj45vcLtrQgLce6/T/Pfs2WEMzhhj2sASRBvFRcdxwqATGjwwB3DJJU4XpLfeCocOBdjYGGM6MUsQ7WBK1hS+2PMFe8r31M/zeOCBB5w7mp54IozBGWNMK1mCaAfe5r8XblnYYP4pp8APfuBUN+3rNI2VG2NMcCxBtINxGePoGdfziGomgPvvh+Ji+N3vwhCYMca0gSWIdhAdFc2kwZMaPA/hlZ0Nl18Ojz0GmzeHIThjjGklSxDtZErWFDbt28T2ku1HLLv7boiJgdtuC0NgxhjTSiFNECIyTUT+LSKbROQWP8tvEJH1IrJWRD4SkcE+y2pFZI07zGu8bWfjrxtSr/79nWci3nwTPv20oyMzxpjWCVmCEBEP8AQwHRgBXCAiIxqt9i8gV1WzgTnA/T7LKlU1xx3OoJMb2Xck6QnpfhMEwE03OU9Z33ijPTxnjOkaQlmCGA9sUtXNqloFvAGc6buCqi5U1Qp38lNgQAjjCakoiSIvK4+Pt3yMv36+k5OdqqZ//APefjsMARpjTAuFMkH0B3b4TO905wXyE+DvPtPxIrJSRD4VkbNCEWB7y8vK45vSb/jP3v/4Xf7jH8Pw4fA//wNVVR0cnDHGtFAoE4T4mee3ckVELgJygQd8Zg9S1VzgQmCWiBwdYNsr3USysjDMfX02dR0CnP4iHngANm2CZ57pyMiMMablQpkgdgIDfaYHAPmNVxKRqcCvgTNUtb5RClXNd183A4uAsf4OoqrPqmququamp6e3X/StcHTq0QzsOdDv7a5ep54KeXlw111QUtKBwRljTAuFMkGsAIaJSJaIxAIzgAZ3I4nIWOAZnOSwx2d+qojEueNpwESg03fBIyJMGTqFhVsWUqd1AdZxShF798If/tDBARpjTAuELEGoag1wLfA+sAGYrapfisjdIuK9K+kBIAn4S6PbWYcDK0Xkc2AhcJ+qdvoEATA1ayp7K/cy/6v5AdcZNw4uvhgefBAeftjuajLGdE7i746brio3N1dXrlwZ1hgO1Rxi7DNjKa8uZ93V60iOS/a73oEDcNllTsdC//Vf8Kc/OXc6GWNMRxKRVe713iPYk9TtLC46jj+d8Sd2lOzg1x//OuB6PXvCX/8K//u/zuvxx8OGDR0YqDHGNMMSRAh8d+B3uXb8tTz+2eMs37E84Hoizi2vH34IRUUwfjzMmdOBgRpjTBMsQYTI76f8noG9BvKTeT/hUE3TPQbl5cHq1TBqlFPddOONUFPTQYEaY0wAliBCJCk2iadPe5oNRRv4/dLfN7v+gAGweDFccw089BBMmQK7dnVAoMYYE4AliBCaPmw6M0fP5A/L/sC6PeuaXT82Fh5/HF55BVascO52+sc/OiBQY4zxwxJEiM2aNote8b24Yt4V1NbVBrXNzJlOq6+JiTB5Mvz+91BaGto4jTGmMUsQIZaWkMYj0x7hn9/8k8c/ezzo7bKznVLEGWfAr38NgwfDb38LYW5NxBgTQSxBdIALRl3AqcNO5baPb2Nr8dagt0tJcW6B/fRTpyRx771Oovj5z2Fr8LsxxphWsQTRAUSEp057iiiJ4qr/d5Xf5sCbcvzx8NZbsH49zJjhNPR3zDFw0UWwdm2IgjbGRDxLEB1kUK9B3DflPj74+gNeXvtyq/YxfDg8/7zTt/UvfuH0KzFmDJx2GixZYk12GGPalzW10YHqtI4TXziRjUUb2XDNBvom9m3T/vbtgyefhEcecR60y8qC730Pvvtd53X0aKeJcWOMCaSppjYsQXSwDYUbyHkmh3OGn8PrP3q9XfZZUQEvvwzvvw/Llx9+fiIxEb7zncNJY8IESEtrl0MaY7oJSxCdzD2L7+H2Rbfztwv+xg+/9cN23bcqbNvmJIpPPnFe16yBWvcO22HD4NvfhkGDnGHw4MPj/fqBx9Ou4RhjOjlLEJ1MVW0Vxz17HN8c+IYfj/0xM0fPJKdfDiL+OuFru4oKWLnSSRaffupcw9i+HYqLG64XE+M80e1NGBkZztCvnzN4x3v2dNqRMsZ0fZYgOqGNRRu5ecHN/P2rv1NdV83wtOHMHD2TC0dfSFZqVofEcOCAkyi8w7ZtDad37fLfd3aPHoeTRr9+TrWVv6FPH+fVEooxnZcliE5sb8Ve/rL+L7z6xass274MgIkDJzJz9EzOG3kefRL6hC02Vdi/30kUBQUNX33H9+51LpLXBnhQPDoa0tMblki8441LKfHxbYu5utrpyrWkxHn6PCrKKRnFxjYcvPNiYix5mchmCaKL2Fq8lde/eJ1XvniF9YXriY6KZtox05g0eBKxnlg84iE6KhpPlPvaaHpgz4GMPmo08dFt+5at0zp2l+2mb2JfPFHBXZRQdUokRUWHB2/iKCqCPXuchOId9uyBOj+9siYkOCUU38HfvIMHDycC36GysuXnGxvrlHJ69Wp6SE11El3fvodfExMtwZiuzRJEF6OqfL77c15d+yqvrXuN/NL8oLeNjopmVN9RHJdxnDNkHkf2UdkBk0bxwWLW7l7bYPhizxdUVFeQEJNA9lHZ5ByVQ04/Zxh91GgSYhLafI61tU6zIb5Jo6Dg8Jd8RYXz6h0aT8fFNfzyTkk58gs9OdlJXFVVTsmiqurIobra2d+BA/4TjrckEujfJD7eSRS+SaNHDzh0yP9QVXV4XNUpXXk8gV89HqcU1Ji/pORdN9DgXR4Tc3jwlqIaz/N4/B+j8byYGOc98CbuQOMizvnW1TmDv3HvexwV5awv4n8cGr6PjcfLKg/xRfFy9lZ9w8iU48nqdTQJCRLwx0ZXKkWqOv8LpaXO36z3ta7OaQG6NcKWIERkGvAI4AH+qKr3NVoeB7wEHAfsBc5X1a3usluBnwC1wHWq+n5zx+suCcJXndZx4NABautqqdVaaupqqK1zX32mq+uq+Xrf16wqWOUM+avYW7kXcJLGyPSRHJfhJIvCikI+3/05a3evZXvJ9vpj9e7RmzFHjSH7qGyOTj2ar/d/zZpda1izaw0lh0oAiJIoju1zbH3CGNZ7GIdqD1FeVU55dfmRr+64oqTEp5ASl0JKfAqpPVKd6fgUUuNT6+f17tGbxJjEkF2wb426Oucfcf9+J6kVFjoloECv3gTmb4iNPTwu4iTKmpqmXxv/i/r7l/X9wm081NY2HK+uPjx4k6S/0lyXEVUDGash6yPI+hgGLYOYg4eXl2bAthNh+4nO655RoA1Lxo2Ts7+E7U2GgT7b+Hjn8/X+6Aj046ay0klmvseKiWn46h0H52/Pdzjis4qupM/AfRRt7t+qty8sCUJEPMB/gO8DO4EVwAWqut5nnf8GslX1ZyIyAzhbVc8XkRHA68B4IBNYAHxLVZtsDrU7JojWUlW2l2yvTxbexFFUUYRHPHw77duM6TeG7L7ZZB/lDJnJmX6/mFWVbSXb6pOFd9hWss3vsaMkisSYRBJjE+tfBaH4YDHFB4vrk00g8dHxpCekk56Y3vDVZ1xRyqvKKasqo7zafXWTkndeRXUFcZ44EmMTSYpJahBPUmxS/XhCTAKCc97K4f8Hf/8bURLldxCR+nGPeIj1xBLjiSEmKqbBeIzHnY6KIUqiGhzT93i+cXjEgyfKU79+W6kqVbVVlFWV1Q8HDpVRUlFOSWUZJZVlVNXU0CO6B/HRPegRnUB8dA/iPYfHe0QnEBfVg4qqQxQUF7HrQBG7ywrZU17E3ooi9lYWsv9QEfurCimt2YuixEgP4qISiJUezhB1+DXe48yPj+pJD+lFvPSih/Sih6QQRy/i6UUsiagKqkqhrOOr2o/ZcOgjNpQvpqLuAABHJ41mfPoUvtcvj/5Jg1m5azkrCpewZt9SCqt2ANBDejE0ZiKDOZEBtSeRVDWM6tpqquuqOFRTRVVtFTV11VTVVVHtHWqrqa2JovZQfP1QczCeqso4airjqaqMp7oinkOVscTGiN+Sim8JJi7O+aKvqXESSk0NVNeoe/yDHKo9SFXdQaqjSonquYuonruoTSigOq6AqthdlEcVUEYBB+p2UV5bQnp8Jntu/qZVfw/hShDfBe5U1R+407cCqOoffNZ5311nuYhEA7uAdOAW33V912vqmJYgmqaq7C7fTWp8KnHRcW3e3/7K/Wwt3kp8dHyDL984T1yTJYDauloOHDpA8cFi9h/cX5849lfuZ2/lXgrLCymscIY95XvqpyuqK5qMJ84T53zxu7EkxCTUl258k0ZXJQjRUdFHDJ4oDx5xfhEriqqiKHVaVz/ufa2pq6G8qpzapn9rtZk3yaclpNEnoQ+CUFlTSWV1JRXVFfXj3tfquupm9+kRDz3jeqIoxQede7SP6X0MeUPymDJ0CpOHTG6ydYJtxdtYsm0JS7cvZen2pWws2thu5+srJirG7+fU+DM7VHOIgzUHGwy+Pwz8SYhJICMpg4zkDDKSMuiX1I+MpAz69+zPJWMuaVW8TSWIUDbE0B/Y4TO9Ezg+0DqqWiMiJUAfd/6njbb1W34SkSuBKwEGDRrULoF3VyJCv6R+7ba/1B6ppPZIbfF2nihP/bZZBH9Lb0V1BYXlhRRVFDmllEYlgeio5v+c67SOiuqKBlVhjZOGb3Lzlizg8JdvndYFHBR1f41WN3itqq06Ytz3x5n3mL7HE5H64/lWKQYaBEFEEKS+VOM7T0TwiKc+iSbFJtUPiTENpz1RHg7WHHS+zH2+yH2/3CuqK4j1xJKe6CQCb0JIS0hzSmUtqCasraulorqCA4cOUHKohJKDJUe8ekufNXU1TBgwgbysPAb1Cv5/fnDKYC5OuZiLx1wMwJ7yPSzbvoxvDnxDXHRcfWmv8eAt/Sl6xBe6d/B+2VfWVDb5GfkOcdFxbiktvsHgOy8xNpF+Sf3qE0FyXHLQ59seQpkg/P11NE6PgdYJZltnpuqzwLPglCBaEqDpWhJiEhicMpjBKYNbvY8oiar/EjSdhyfKQ3JcMslxyfT3/1uw3fVN7Ms5w8/pkGN1VaFszXUnMNBnegDQ+Hac+nXcKqZewL4gtzXGGBNCoUwQK4BhIpIlIrHADGBeo3XmAZe64+cCH6tT7p4HzBCROBHJAoYBn4UwVmOMMY2ErIrJvaZwLfA+zm2uz6vqlyJyN7BSVecBfwJeFpFNOCWHGe62X4rIbGA9UANc09wdTMYYY9qXPShnjDERrKm7mKxHOWOMMX5ZgjDGGOOXJQhjjDF+WYIwxhjjV7e6SC0ihUDjBoLSgKIwhNOe7Bw6BzuHzqE7nAN0nvMYrKrp/hZ0qwThj4isDHSFvquwc+gc7Bw6h+5wDtA1zsOqmIwxxvhlCcIYY4xfkZAgng13AO3AzqFzsHPoHLrDOUAXOI9ufw3CGGNM60RCCcIYY0wrWIIwxhjjV7dNECIyTUT+LSKbROSWcMfTWiKyVUS+EJE1ItIlWiIUkedFZI+IrPOZ11tEPhSRr9zXlndF14ECnMOdIvKN+1msEZFTwxljc0RkoIgsFJENIvKliPzCnd9lPosmzqHLfBYiEi8in4nI5+453OXOzxKRf7qfw5tutwidSre8BiEiHuA/wPdxOh9aAVygquvDGlgriMhWIFdVO8MDNUERkZOAMuAlVR3lzrsf2Keq97kJO1VVbw5nnE0JcA53AmWq+mA4YwuWiGQAGaq6WkSSgVXAWcBldJHPoolzOI8u8lmI0/dqoqqWiUgMsAz4BXAD8JaqviEiTwOfq+pT4Yy1se5aghgPbFLVzapaBbwBnBnmmCKGqi7B6d/D15nAi+74izj/5J1WgHPoUlS1QFVXu+OlwAacvt27zGfRxDl0Geoocydj3EGBPGCOO79Tfg7dNUH0B3b4TO+ki/1R+VDgAxFZJSJXhjuYNjhKVQvA+acH+oY5nta6VkTWulVQnbZqpjERGQKMBf5JF/0sGp0DdKHPQkQ8IrIG2AN8CHwNFKtqjbtKp/yO6q4JQvzM66p1aRNVdRwwHbjGrfow4fEUcDSQAxQAD4U3nOCISBLwV+B6VT0Q7nhaw885dKnPQlVrVTUHGIBTwzHc32odG1XzumuC2AkM9JkeAOSHKZY2UdV893UPMBfnj6sr2u3WJ3vrlfeEOZ4WU9Xd7j96HfAcXeCzcOu8/wq8qqpvubO71Gfh7xy64mcBoKrFwCJgApAiIt5unzvld1R3TRArgGHuXQKxOH1dzwtzTC0mIonuhTlEJBE4BVjX9Fad1jzgUnf8UuCdMMbSKt4vVdfZdPLPwr04+idgg6o+7LOoy3wWgc6hK30WIpIuIinueA9gKs61lIXAue5qnfJz6JZ3MQG4t73NAjzA86r6uzCH1GIiMhSn1AAQDbzWFc5DRF4HJuM0Z7wbuAN4G5gNDAK2A/+lqp32InCAc5iMU6WhwFbgKm9dfmckIicAS4EvgDp39m04dfhd4rNo4hwuoIt8FiKSjXMR2oPzo3y2qt7t/n+/AfQG/gVcpKqHwhfpkbptgjDGGNM23bWKyRhjTBtZgjDGGOOXJQhjjDF+WYIwxhjjlyUIY4wxflmCMCaMRGSyiPy/cMdhjD+WIIwxxvhlCcKYIIjIRW6b/mtE5Bm38bUyEXlIRFaLyEciku6umyMin7oNyc31NiQnIseIyAK3X4DVInK0u/skEZkjIhtF5FX36WFE5D4RWe/up9M3a226H0sQxjRDRIYD5+M0nJgD1AIzgURgtduY4mKcp60BXgJuVtVsnCeAvfNfBZ5Q1THA93AamQOnhdLrgRHAUGCiiPTGaUJipLufe0N7lsYcyRKEMc2bAhwHrHCbbJ6C80VeB7zprvMKcIKI9AJSVHWxO/9F4CS3Ta3+qjoXQFUPqmqFu85nqrrTbXhuDTAEOAAcBP4oIucA3nWN6TCWIIxpngAvqmqOOxyrqnf6Wa+pdmv8NUHv5dv+Ti0Q7fYTMB6nFdOzgPdaGLMxbWYJwpjmfQScKyJ9ob5P58E4/z/e1jgvBJapagmwX0ROdOdfDCx2+zDYKSJnufuIE5GEQAd0+z/oparzcaqfckJxYsY0Jbr5VYyJbKq6XkR+g9OzXxRQDVwDlAMjRWQVUIJznQKcppufdhPAZuByd/7FwDMicre7j/9q4rDJwDsiEo9T+vhlO5+WMc2y1lyNaSURKVPVpHDHYUyoWBWTMcYYv6wEYYwxxi8rQRhjjPHLEoQxxhi/LEEYY4zxyxKEMcYYvyxBGGOM8ev/A5Co2ruLTKaMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveLogMsg('Retrieving training and validation loss...')\n",
    "\n",
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "\n",
    "# Refs: https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
