{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import _pickle as pk\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing imports and config... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'patience': 10,\n",
    "    'batch': 32,\n",
    "    'epoch': 100,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.99,\n",
    "    'emb_size': 64,\n",
    "    'lstm_size': 128,\n",
    "    'pred_size': 10,\n",
    "    'test_file': \"../data/raw/test.txt\",\n",
    "    'logfile': \"dataset-batch-noattn.log\",\n",
    "    'lossfile': 'dataset-batch-noattn.loss',\n",
    "    'checkpoint': \"dataset-batch-noattn.pt\"\n",
    "}\n",
    "\n",
    "open(config['logfile'], 'w').close()\n",
    "def saveLogMsg(msg):\n",
    "    print(msg, \"\\n\")\n",
    "    with open(config['logfile'], \"a\") as myfile:\n",
    "        myfile.write(msg + \"\\n\")\n",
    "\n",
    "saveLogMsg(\"Initializing imports and config...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for train and valid... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(5, 10)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])\n",
    "\n",
    "saveLogMsg(\"Dataset for train and valid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab for source and target... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']\n",
    "\n",
    "saveLogMsg(\"Vocab for source and target...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dataset through Vocab... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Mapping dataset through Vocab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset from ../data/raw/test.txt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(config['test_file'], delimiter='\\t', header=None, usecols=[0,1])\n",
    "test_inp, test_out = test_data[0], test_data[1]  \n",
    "\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Loading test dataset from {}.\".format(config['test_file']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, enc_inputs):\n",
    "        batch_inputs = copy.deepcopy(enc_inputs)\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        x_tensor = [torch.tensor(sample).to(device) for sample in batch_inputs]\n",
    "        x_pad = pad_sequence(x_tensor, batch_first=True, padding_value=0) # (batch, seqlen) \n",
    "        x_emb = self.emb(x_pad) # (batch, seqlen, emb_dim) \n",
    "        x_emb = self.drop(x_emb)\n",
    "        \n",
    "        x_len = [len(sample) for sample in batch_inputs]\n",
    "        x_pack = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
    "        outs_pack, (h_n, c_n) = self.lstm(x_pack)\n",
    "        outs, _ = pad_packed_sequence(outs_pack, batch_first=True)\n",
    "            \n",
    "        if self.z_index == 1:\n",
    "            return h_n[0], c_n[0] # (seqlen, batch, lstm_dim)\n",
    "        else:\n",
    "            return outs # (batch, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "saveLogMsg(\"encoder:\\n{}\".format(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder:\n",
      "Decoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (clf): Linear(in_features=128, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, dropout=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.clf = nn.Linear(lstm_size, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=tgt_vocab.stoi['<pad>'])\n",
    "    \n",
    "    def pad_targets(self, targets):\n",
    "        last_token = tgt_vocab.stoi['<stop>']\n",
    "        pad_token = tgt_vocab.stoi['<pad>']\n",
    "        maxlen = max([len(target) for target in targets])\n",
    "        for i in range(len(targets)): \n",
    "            targets[i].append(last_token) #added last token\n",
    "            targets[i].extend([pad_token] * (maxlen + 1 - len(targets[i]))) #added pad token\n",
    "        return targets, maxlen\n",
    "    \n",
    "    def forward(self, state, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "\n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            emb = self.drop(emb) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state \n",
    "            q_i = self.drop(q_i) # (batch, lstm_dim)\n",
    "            \n",
    "            scores = self.clf(q_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            curr_tokens = next_tokens\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        return batch_loss\n",
    "\n",
    "    def predict(self, state, curr_token, last_token, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "        \n",
    "        batch_preds = []\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            h_i, _ = state \n",
    "            \n",
    "            scores = self.clf(h_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "\n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        return batch_preds\n",
    "\n",
    "    def evaluate(self, state, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = state[0].shape[0]\n",
    "        \n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_preds, batch_loss = [], 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            h_i, _ = state\n",
    "            \n",
    "            scores = self.clf(h_i) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        \n",
    "        return batch_preds, batch_loss\n",
    "\n",
    "decoder = Decoder(vocab_size=len(tgt_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'])\n",
    "saveLogMsg(\"decoder:\\n{}\".format(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    batch_x = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds = decoder.predict(encoder(batch_x), START_IX, STOP_IX, pred_size)\n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_x = []\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample_loss = 0.0\n",
    "    batch_x, batch_y = [], []\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            batch_y.append(sample_y[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds, batch_loss = decoder.evaluate(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "                \n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_y = map_prediction(batch_y)\n",
    "                actuals.extend(batch_y)\n",
    "                \n",
    "                sample_loss += batch_loss.item()\n",
    "                batch_x, batch_y = [], []\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    batch_x, batch_y = [], []\n",
    "\n",
    "    for i in range(len(train_x)):\n",
    "        batch_x.append(train_x[i])\n",
    "        batch_y.append(train_y[i])\n",
    "\n",
    "        if len(batch_x) == batch_size or i == len(train_x) - 1:\n",
    "            batch_loss = decoder(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_x, batch_y = [], []\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, '', patience_track+1\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * ', 0\n",
    "\n",
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "    decoder = Decoder(vocab_size=len(tgt_vocab),\n",
    "                      emb_dim=config['emb_size'], \n",
    "                      lstm_size=config['lstm_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "def getCurrentTime():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out):\n",
    "    predictions = predict(encoder, decoder, sample_x, config['batch'], config['pred_size'])\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    patience_track = 0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.zero_grad(); enc_optim.zero_grad()\n",
    "        decoder.zero_grad(); dec_optim.zero_grad()\n",
    "        \n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track, patience_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track)\n",
    "        test_acc = getAccuracyScore(encoder, decoder, test_x, test_out)\n",
    "        \n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            epoch_msg = '[{}] Epoch {}:\\n [TRAIN] Loss: {:.6f}'.format(getCurrentTime(), epoch, train_loss)\n",
    "            epoch_msg += ' [DEV] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "            epoch_msg += ' [TEST] Acc: {:.6f}'.format(test_acc)\n",
    "            saveLogMsg(epoch_msg + epoch_track)\n",
    "            \n",
    "        if patience_track == int(config['patience']):\n",
    "            saveLogMsg('No accuracy improvment for {} consecutive epochs, stopping training...'.format(config['patience']))\n",
    "            break\n",
    "    \n",
    "    best_encoder, best_decoder, _ = load_best_model()\n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    return best_encoder, best_decoder, keep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with encoder and decoder... \n",
      "\n",
      "[2020-04-10 04:51:43.566155] Epoch 1:\n",
      " [TRAIN] Loss: 2.114312 [DEV] Loss: 1.463494, Acc: 0.190000 [TEST] Acc: 0.064000 *  \n",
      "\n",
      "[2020-04-10 04:52:04.753786] Epoch 2:\n",
      " [TRAIN] Loss: 0.616376 [DEV] Loss: 0.139585, Acc: 0.929800 [TEST] Acc: 0.253600 *  \n",
      "\n",
      "[2020-04-10 04:52:24.577570] Epoch 3:\n",
      " [TRAIN] Loss: 0.198423 [DEV] Loss: 0.058169, Acc: 0.968600 [TEST] Acc: 0.258800 *  \n",
      "\n",
      "[2020-04-10 04:52:44.873568] Epoch 4:\n",
      " [TRAIN] Loss: 0.094871 [DEV] Loss: 0.039265, Acc: 0.976200 [TEST] Acc: 0.271800 *  \n",
      "\n",
      "[2020-04-10 04:53:05.823809] Epoch 5:\n",
      " [TRAIN] Loss: 0.055907 [DEV] Loss: 0.022541, Acc: 0.986800 [TEST] Acc: 0.269000 *  \n",
      "\n",
      "[2020-04-10 04:53:25.659240] Epoch 6:\n",
      " [TRAIN] Loss: 0.037311 [DEV] Loss: 0.020049, Acc: 0.993400 [TEST] Acc: 0.288000 *  \n",
      "\n",
      "[2020-04-10 04:53:46.167849] Epoch 7:\n",
      " [TRAIN] Loss: 0.024315 [DEV] Loss: 0.035880, Acc: 0.990600 [TEST] Acc: 0.287600 \n",
      "\n",
      "[2020-04-10 04:54:06.704390] Epoch 8:\n",
      " [TRAIN] Loss: 0.020450 [DEV] Loss: 0.012519, Acc: 0.995600 [TEST] Acc: 0.258800 *  \n",
      "\n",
      "[2020-04-10 04:54:26.536530] Epoch 9:\n",
      " [TRAIN] Loss: 0.017563 [DEV] Loss: 0.011160, Acc: 0.995400 [TEST] Acc: 0.272800 \n",
      "\n",
      "[2020-04-10 04:54:47.582530] Epoch 10:\n",
      " [TRAIN] Loss: 0.013758 [DEV] Loss: 0.009321, Acc: 0.998000 [TEST] Acc: 0.271200 *  \n",
      "\n",
      "[2020-04-10 04:55:07.580323] Epoch 11:\n",
      " [TRAIN] Loss: 0.012045 [DEV] Loss: 0.007637, Acc: 0.997800 [TEST] Acc: 0.277600 \n",
      "\n",
      "[2020-04-10 04:55:27.345030] Epoch 12:\n",
      " [TRAIN] Loss: 0.010659 [DEV] Loss: 0.002075, Acc: 0.999400 [TEST] Acc: 0.274600 *  \n",
      "\n",
      "[2020-04-10 04:55:48.624897] Epoch 13:\n",
      " [TRAIN] Loss: 0.009096 [DEV] Loss: 0.007040, Acc: 0.998600 [TEST] Acc: 0.271800 \n",
      "\n",
      "[2020-04-10 04:56:08.435231] Epoch 14:\n",
      " [TRAIN] Loss: 0.008772 [DEV] Loss: 0.004080, Acc: 0.999000 [TEST] Acc: 0.262200 \n",
      "\n",
      "[2020-04-10 04:56:28.199745] Epoch 15:\n",
      " [TRAIN] Loss: 0.006951 [DEV] Loss: 0.003872, Acc: 0.998800 [TEST] Acc: 0.269000 \n",
      "\n",
      "[2020-04-10 04:56:49.405117] Epoch 16:\n",
      " [TRAIN] Loss: 0.007811 [DEV] Loss: 0.012175, Acc: 0.997000 [TEST] Acc: 0.258000 \n",
      "\n",
      "[2020-04-10 04:57:09.175906] Epoch 17:\n",
      " [TRAIN] Loss: 0.006576 [DEV] Loss: 0.030216, Acc: 0.994800 [TEST] Acc: 0.281000 \n",
      "\n",
      "[2020-04-10 04:57:29.288167] Epoch 18:\n",
      " [TRAIN] Loss: 0.005551 [DEV] Loss: 0.006509, Acc: 0.998600 [TEST] Acc: 0.279000 \n",
      "\n",
      "[2020-04-10 04:57:50.398503] Epoch 19:\n",
      " [TRAIN] Loss: 0.005115 [DEV] Loss: 0.003219, Acc: 0.999200 [TEST] Acc: 0.284800 \n",
      "\n",
      "[2020-04-10 04:58:10.247161] Epoch 20:\n",
      " [TRAIN] Loss: 0.004758 [DEV] Loss: 0.003510, Acc: 0.999000 [TEST] Acc: 0.280200 \n",
      "\n",
      "[2020-04-10 04:58:30.497407] Epoch 21:\n",
      " [TRAIN] Loss: 0.004925 [DEV] Loss: 0.001530, Acc: 0.999400 [TEST] Acc: 0.286600 \n",
      "\n",
      "[2020-04-10 04:58:51.362842] Epoch 22:\n",
      " [TRAIN] Loss: 0.004595 [DEV] Loss: 0.003687, Acc: 0.999000 [TEST] Acc: 0.265400 \n",
      "\n",
      "No accuracy improvment for 10 consecutive epochs, stopping training... \n",
      "\n",
      "Training done... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True: #not os.path.exists(config['checkpoint']):\n",
    "    saveLogMsg(\"Training with encoder and decoder...\")\n",
    "    training_loop(encoder, decoder, train_x, train_y, config['epoch'], config['batch'], print_every=1)\n",
    "    saveLogMsg('Training done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning best model from epoch 12 with loss 0.002075 and accuracy 0.999400. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "encoder, decoder, state = load_best_model()\n",
    "saveLogMsg('Returning best model from epoch {} with loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training and validation loss... \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveLogMsg('Retrieving training and validation loss...')\n",
    "\n",
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "\n",
    "# Refs: https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
