{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import _pickle as pk\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing imports and config... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'patience': 10,\n",
    "    'batch': 32,\n",
    "    'epoch': 100,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.99,\n",
    "    'emb_size': 64,\n",
    "    'lstm_size': 128,\n",
    "    'attn_size': 100,\n",
    "    'pred_size': 10,\n",
    "    'test_file': \"../data/raw/test.txt\",\n",
    "    'logfile': \"model_batch_withattn.log\",\n",
    "    'lossfile': 'model_batch_withattn.loss',\n",
    "    'checkpoint': \"model_batch_withattn.pt\"\n",
    "}\n",
    "\n",
    "open(config['logfile'], 'w').close()\n",
    "def saveLogMsg(msg):\n",
    "    print(msg, \"\\n\")\n",
    "    with open(config['logfile'], \"a\") as myfile:\n",
    "        myfile.write(msg + \"\\n\")\n",
    "\n",
    "saveLogMsg(\"Initializing imports and config...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for train and valid... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(1, 3)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])\n",
    "\n",
    "saveLogMsg(\"Dataset for train and valid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab for source and target... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']\n",
    "\n",
    "saveLogMsg(\"Vocab for source and target...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dataset through Vocab... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Mapping dataset through Vocab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, enc_inputs):\n",
    "        batch_inputs = copy.deepcopy(enc_inputs)\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        x_tensor = [torch.tensor(sample).to(device) for sample in batch_inputs]\n",
    "        x_pad = pad_sequence(x_tensor, batch_first=True, padding_value=0) # (batch, seqlen) \n",
    "        x_emb = self.emb(x_pad) # (batch, seqlen, emb_dim) \n",
    "        x_emb = self.drop(x_emb)\n",
    "        \n",
    "        x_len = [len(sample) for sample in batch_inputs]\n",
    "        x_pack = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
    "        outs_pack, (h_n, c_n) = self.lstm(x_pack)\n",
    "        outs, _ = pad_packed_sequence(outs_pack, batch_first=True)\n",
    "            \n",
    "        if self.z_index == 1:\n",
    "            return h_n[0], c_n[0] # (seqlen, batch, lstm_dim)\n",
    "        else:\n",
    "            return outs # (batch, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=0)\n",
    "saveLogMsg(\"encoder:\\n{}\".format(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, attn_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W = nn.Linear(input_dim, attn_dim)\n",
    "        self.v = nn.Linear(attn_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, dec_hidden, enc_outs):\n",
    "        # enc_outs -> (batch, seqlen, hidden)\n",
    "        # dec_hidden -> (batch, hidden)\n",
    "        \n",
    "        seqlen = enc_outs.size(1)\n",
    "        \n",
    "        repeat_h = dec_hidden.unsqueeze(1)  # make room to repeat on seqlen dim\n",
    "        repeat_h = repeat_h.repeat(1, seqlen, 1)  # (1, seqlen, hidden)\n",
    "\n",
    "        concat_h = torch.cat((enc_outs, repeat_h), dim=2) # (1, seqlen, hidden*2)\n",
    "        \n",
    "        scores = self.v(torch.tanh(self.W(concat_h))) # (1, seqlen, 1)\n",
    "        probs = torch.softmax(scores, dim=1)\n",
    "        \n",
    "        weighted = enc_outs * probs # (1, seqlen, hidden)\n",
    "        \n",
    "        context = torch.sum(weighted, dim=1, keepdim=False) # (1, hidden)\n",
    "        combined = torch.cat((dec_hidden, context), dim=1)  # (1, hidden*2)\n",
    "        \n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder:\n",
      "AttentionDecoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (attn): Attention(\n",
      "    (W): Linear(in_features=256, out_features=100, bias=True)\n",
      "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=256, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, attn_size, dropout=0.5):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        \n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.attn = Attention(lstm_size * 2, attn_size)\n",
    "        self.clf = nn.Linear(lstm_size * 2, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\", ignore_index=tgt_vocab.stoi['<pad>'])\n",
    "        \n",
    "    def init_state(self, batch_size, device):\n",
    "        h_0 = torch.zeros(batch_size, self.lstm_size).to(device)  # (batch, hidden_size)\n",
    "        c_0 = torch.zeros(batch_size, self.lstm_size).to(device)  # (batch, hidden_size)\n",
    "        return h_0, c_0\n",
    "    \n",
    "    def pad_targets(self, targets):\n",
    "        last_token = tgt_vocab.stoi['<stop>']\n",
    "        pad_token = tgt_vocab.stoi['<pad>']\n",
    "        maxlen = max([len(target) for target in targets])\n",
    "        for i in range(len(targets)): \n",
    "            targets[i].append(last_token) #added last token\n",
    "            targets[i].extend([pad_token] * (maxlen + 1 - len(targets[i]))) #added pad token\n",
    "        return targets, maxlen\n",
    "            \n",
    "    def forward(self, enc_outs, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = enc_outs.shape[0]\n",
    "        state = self.init_state(batch_size, device) # (batch, lstm_dim)\n",
    "        \n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            emb = self.drop(emb) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state \n",
    "            q_i = self.drop(q_i) # (batch, lstm_dim)\n",
    "            \n",
    "            combined = self.attn(q_i, enc_outs) # (batch, lstm_dim * 2)\n",
    "            scores = self.clf(combined) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            curr_tokens = next_tokens\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        return batch_loss\n",
    "    \n",
    "    def predict(self, enc_outs, curr_token, last_token, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = enc_outs.shape[0]\n",
    "        state = self.init_state(batch_size, device) # (batch, lstm_dim)\n",
    "        \n",
    "        batch_preds = []\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state \n",
    "            \n",
    "            combined = self.attn(q_i, enc_outs) # (batch, lstm_dim * 2)\n",
    "            scores = self.clf(combined) # (batch, tgt_vocab)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "\n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        return batch_preds\n",
    "    \n",
    "    def evaluate(self, enc_outs, dec_targets, curr_token, last_token):\n",
    "        batch_targets = copy.deepcopy(dec_targets)\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size = enc_outs.shape[0]\n",
    "        state = self.init_state(batch_size, device) # (batch, lstm_dim)\n",
    "        \n",
    "        batch_targets, maxlen = self.pad_targets(batch_targets)\n",
    "        \n",
    "        batch_preds, batch_loss = [], 0.0\n",
    "        curr_tokens = [curr_token] * batch_size\n",
    "        for i in range(maxlen + 1):\n",
    "            inputs = torch.tensor(curr_tokens).to(device) # (batch)\n",
    "            \n",
    "            emb = self.emb(inputs) # (batch, emb_dim)\n",
    "            \n",
    "            state = self.lstm(emb, state) # (batch, lstm_dim)\n",
    "            q_i, _ = state\n",
    "            \n",
    "            combined = self.attn(q_i, enc_outs) # (batch, lstm_dim * 2)\n",
    "            scores = self.clf(combined) # (batch, tgt_vocab)\n",
    "            \n",
    "            next_tokens = [targets[i] for targets in batch_targets]\n",
    "            targets = torch.tensor(next_tokens).to(device) # (batch)\n",
    "            batch_loss += self.objective(scores, targets) # (batch)\n",
    "            \n",
    "            pred_tokens = torch.argmax(torch.softmax(scores, dim=1), dim=1) # (batch)\n",
    "            curr_tokens = pred_tokens\n",
    "            batch_preds.append(pred_tokens.tolist())\n",
    "        \n",
    "        maskcount = [np.count_nonzero(targets) for targets in batch_targets]\n",
    "        maskcount = torch.tensor(maskcount, dtype=torch.float32).to(device)\n",
    "        batch_loss = (batch_loss/maskcount).sum()\n",
    "        \n",
    "        batch_preds = np.array(batch_preds).T.tolist()\n",
    "        for ix, _ in enumerate(batch_preds):\n",
    "            if last_token in batch_preds[ix]:\n",
    "                last_token_ix = batch_preds[ix].index(last_token)\n",
    "                batch_preds[ix] = batch_preds[ix][:last_token_ix]\n",
    "        \n",
    "        return batch_preds, batch_loss\n",
    "\n",
    "decoder = AttentionDecoder(vocab_size=len(tgt_vocab), \n",
    "                           emb_dim=config['emb_size'], \n",
    "                           lstm_size=config['lstm_size'], \n",
    "                           attn_size=config['attn_size'])\n",
    "saveLogMsg(\"decoder:\\n{}\".format(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    batch_x = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds = decoder.predict(encoder(batch_x), START_IX, STOP_IX, pred_size)\n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_x = []\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample_loss = 0.0\n",
    "    batch_x, batch_y = [], []\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            batch_y.append(sample_y[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds, batch_loss = decoder.evaluate(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "                \n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_y = map_prediction(batch_y)\n",
    "                actuals.extend(batch_y)\n",
    "                \n",
    "                sample_loss += batch_loss.item()\n",
    "                batch_x, batch_y = [], []\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    batch_x, batch_y = [], []\n",
    "\n",
    "    for i in range(len(train_x)):\n",
    "        batch_x.append(train_x[i])\n",
    "        batch_y.append(train_y[i])\n",
    "\n",
    "        if len(batch_x) == batch_size or i == len(train_x) - 1:\n",
    "            batch_loss = decoder(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_x, batch_y = [], []\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, '', patience_track+1\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * ', 0\n",
    "\n",
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=0)\n",
    "    decoder = AttentionDecoder(vocab_size=len(tgt_vocab), \n",
    "                               emb_dim=config['emb_size'], \n",
    "                               lstm_size=config['lstm_size'], \n",
    "                               attn_size=config['attn_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    patience_track = 0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.zero_grad(); enc_optim.zero_grad()\n",
    "        decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track, patience_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track)\n",
    "\n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            epoch_msg = 'Epoch {} - [TRAIN] Loss: {:.6f}'.format(epoch, train_loss)\n",
    "            epoch_msg += ' [DEV] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "            saveLogMsg(epoch_msg + epoch_track)\n",
    "            \n",
    "        if patience_track == int(config['patience']):\n",
    "            saveLogMsg('No accuracy improvment for {} consecutive epochs, stopping training...'.format(config['patience']))\n",
    "            break\n",
    "    \n",
    "    best_encoder, best_decoder, _ = load_best_model()\n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    return best_encoder, best_decoder, keep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with encoder and decoder... \n",
      "\n",
      "Epoch 1 - [TRAIN] Loss: 1.326269 [DEV] Loss: 1.308529, Acc: 0.734600 *  \n",
      "\n",
      "Epoch 2 - [TRAIN] Loss: 0.277904 [DEV] Loss: 0.377637, Acc: 0.935000 *  \n",
      "\n",
      "Epoch 3 - [TRAIN] Loss: 0.154015 [DEV] Loss: 0.202143, Acc: 0.969000 *  \n",
      "\n",
      "Epoch 4 - [TRAIN] Loss: 0.107612 [DEV] Loss: 0.149917, Acc: 0.976800 *  \n",
      "\n",
      "Epoch 5 - [TRAIN] Loss: 0.086642 [DEV] Loss: 0.083299, Acc: 0.987800 *  \n",
      "\n",
      "Epoch 6 - [TRAIN] Loss: 0.082515 [DEV] Loss: 0.109729, Acc: 0.983000 \n",
      "\n",
      "Epoch 7 - [TRAIN] Loss: 0.086080 [DEV] Loss: 0.140087, Acc: 0.978600 \n",
      "\n",
      "Epoch 8 - [TRAIN] Loss: 0.074891 [DEV] Loss: 0.065171, Acc: 0.991400 *  \n",
      "\n",
      "Epoch 9 - [TRAIN] Loss: 0.063610 [DEV] Loss: 0.054420, Acc: 0.992800 *  \n",
      "\n",
      "Epoch 10 - [TRAIN] Loss: 0.060919 [DEV] Loss: 0.044879, Acc: 0.994400 *  \n",
      "\n",
      "Epoch 11 - [TRAIN] Loss: 0.055709 [DEV] Loss: 0.069564, Acc: 0.992600 \n",
      "\n",
      "Epoch 12 - [TRAIN] Loss: 0.053759 [DEV] Loss: 0.044022, Acc: 0.993600 \n",
      "\n",
      "Epoch 13 - [TRAIN] Loss: 0.052262 [DEV] Loss: 0.055785, Acc: 0.992000 \n",
      "\n",
      "Epoch 14 - [TRAIN] Loss: 0.046426 [DEV] Loss: 0.038919, Acc: 0.996600 *  \n",
      "\n",
      "Epoch 15 - [TRAIN] Loss: 0.045396 [DEV] Loss: 0.022515, Acc: 0.996400 \n",
      "\n",
      "Epoch 16 - [TRAIN] Loss: 0.044725 [DEV] Loss: 0.049286, Acc: 0.993800 \n",
      "\n",
      "Epoch 17 - [TRAIN] Loss: 0.043180 [DEV] Loss: 0.047444, Acc: 0.995400 \n",
      "\n",
      "Epoch 18 - [TRAIN] Loss: 0.043407 [DEV] Loss: 0.022144, Acc: 0.997200 *  \n",
      "\n",
      "Epoch 19 - [TRAIN] Loss: 0.038683 [DEV] Loss: 0.032425, Acc: 0.996400 \n",
      "\n",
      "Epoch 20 - [TRAIN] Loss: 0.041567 [DEV] Loss: 0.030613, Acc: 0.996000 \n",
      "\n",
      "Epoch 21 - [TRAIN] Loss: 0.042833 [DEV] Loss: 0.040503, Acc: 0.996000 \n",
      "\n",
      "Epoch 22 - [TRAIN] Loss: 0.039456 [DEV] Loss: 0.030600, Acc: 0.996600 \n",
      "\n",
      "Epoch 23 - [TRAIN] Loss: 0.040326 [DEV] Loss: 0.032159, Acc: 0.995000 \n",
      "\n",
      "Epoch 24 - [TRAIN] Loss: 0.043830 [DEV] Loss: 0.028464, Acc: 0.994600 \n",
      "\n",
      "Epoch 25 - [TRAIN] Loss: 0.042994 [DEV] Loss: 0.052393, Acc: 0.994800 \n",
      "\n",
      "Epoch 26 - [TRAIN] Loss: 0.042672 [DEV] Loss: 0.056151, Acc: 0.993400 \n",
      "\n",
      "Epoch 27 - [TRAIN] Loss: 0.039462 [DEV] Loss: 0.029573, Acc: 0.996600 \n",
      "\n",
      "Epoch 28 - [TRAIN] Loss: 0.040575 [DEV] Loss: 0.014874, Acc: 0.998400 *  \n",
      "\n",
      "Epoch 29 - [TRAIN] Loss: 0.041296 [DEV] Loss: 0.029702, Acc: 0.996400 \n",
      "\n",
      "Epoch 30 - [TRAIN] Loss: 0.038535 [DEV] Loss: 0.017465, Acc: 0.997800 \n",
      "\n",
      "Epoch 31 - [TRAIN] Loss: 0.036948 [DEV] Loss: 0.011558, Acc: 0.999000 *  \n",
      "\n",
      "Epoch 32 - [TRAIN] Loss: 0.039509 [DEV] Loss: 0.058063, Acc: 0.995400 \n",
      "\n",
      "Epoch 33 - [TRAIN] Loss: 0.041468 [DEV] Loss: 0.018154, Acc: 0.998000 \n",
      "\n",
      "Epoch 34 - [TRAIN] Loss: 0.047692 [DEV] Loss: 0.007775, Acc: 0.999000 \n",
      "\n",
      "Epoch 35 - [TRAIN] Loss: 0.043887 [DEV] Loss: 0.030024, Acc: 0.996400 \n",
      "\n",
      "Epoch 36 - [TRAIN] Loss: 0.042824 [DEV] Loss: 0.025703, Acc: 0.995600 \n",
      "\n",
      "Epoch 37 - [TRAIN] Loss: 0.045349 [DEV] Loss: 0.020100, Acc: 0.998200 \n",
      "\n",
      "Epoch 38 - [TRAIN] Loss: 0.045571 [DEV] Loss: 0.015790, Acc: 0.997800 \n",
      "\n",
      "Epoch 39 - [TRAIN] Loss: 0.044526 [DEV] Loss: 0.022560, Acc: 0.998000 \n",
      "\n",
      "Epoch 40 - [TRAIN] Loss: 0.045641 [DEV] Loss: 0.021431, Acc: 0.997600 \n",
      "\n",
      "Epoch 41 - [TRAIN] Loss: 0.051122 [DEV] Loss: 0.018581, Acc: 0.998400 \n",
      "\n",
      "No accuracy improvment for 10 consecutive epochs, stopping training... \n",
      "\n",
      "Training done... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "if True: #not os.path.exists(config['checkpoint']):\n",
    "    saveLogMsg(\"Training with encoder and decoder...\")\n",
    "    encoder, decoder, keep_loss = training_loop(encoder, decoder, \n",
    "                                                train_x, train_y, \n",
    "                                                config['epoch'], config['batch'], \n",
    "                                                print_every=1)\n",
    "    saveLogMsg('Training done...')\n",
    "else:\n",
    "    with open(config['lossfile'], 'rb') as lossfile:\n",
    "        keep_loss = pk.load(lossfile)\n",
    "    encoder, decoder, state = load_best_model()\n",
    "    saveLogMsg('Returning best model from epoch {} with loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training and validation loss... \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveLogMsg('Retrieving training and validation loss...')\n",
    "\n",
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "\n",
    "# Refs: https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset from ../data/raw/test.txt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "saveLogMsg(\"Loading test dataset from {}.\".format(config['test_file']))\n",
    "\n",
    "test_inp, test_out = [], []\n",
    "with open(config['test_file'], 'r') as testfile:\n",
    "    for eachline in testfile:\n",
    "        eachline = eachline.strip()\n",
    "        if eachline:\n",
    "            eachline = eachline.split()\n",
    "            if len(eachline) == 2:\n",
    "                test_inp.append(eachline[0])\n",
    "                test_out.append(eachline[1])\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score = 0.9742 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out):\n",
    "    predictions = predict(encoder, decoder, sample_x, config['batch'], config['pred_size'])\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "saveLogMsg(\"Test accuracy score = {}\".format(getAccuracyScore(encoder, decoder, test_x, test_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
