{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import _pickle as pk\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing imports and config... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'patience': 10,\n",
    "    'batch': 32,\n",
    "    'epoch': 1000,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.99,\n",
    "    'emb_size': 64,\n",
    "    'lstm_size': 128,\n",
    "    'pred_size': 10,\n",
    "    'testfile': \"../data/raw/test.txt\",\n",
    "    'logfile': \"model_single_noattn.log\",\n",
    "    'lossfile': 'model_single_noattn.loss',\n",
    "    'checkpoint': \"model_single_noattn.pt\"\n",
    "}\n",
    "\n",
    "open(config['logfile'], 'w').close()\n",
    "def saveLogMsg(msg):\n",
    "    print(msg, \"\\n\")\n",
    "    with open(config['logfile'], \"a\") as myfile:\n",
    "        myfile.write(msg + \"\\n\")\n",
    "        \n",
    "saveLogMsg(\"Initializing imports and config...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for train and valid... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(1, 3)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])\n",
    "\n",
    "saveLogMsg(\"Dataset for train and valid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab for source and target... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']\n",
    "\n",
    "saveLogMsg(\"Vocab for source and target...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dataset through Vocab... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Mapping dataset through Vocab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        seq = torch.tensor([inputs]).to(device) # (1, seqlen)\n",
    "        emb = self.emb(seq) # (1, seqlen, emb_dim)\n",
    "        emb = self.drop(emb) \n",
    "        \n",
    "        outs, (h_n, c_n) = self.lstm(emb)\n",
    "        \n",
    "        if self.z_index == 1:\n",
    "            return h_n[0], c_n[0] # (seqlen, lstm_dim)\n",
    "        else:\n",
    "            return outs # (1, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "saveLogMsg(\"encoder:\\n{}\".format(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder:\n",
      "Decoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (clf): Linear(in_features=128, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, dropout=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.clf = nn.Linear(lstm_size, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        \n",
    "    def forward(self, state, targets, curr_token, last_token):\n",
    "        device = next(self.parameters()).device\n",
    "    \n",
    "        loss = 0\n",
    "        shifted = targets + [last_token]\n",
    "        for i in range(len(shifted)):\n",
    "            inp = torch.tensor([curr_token]).to(device)\n",
    "            \n",
    "            emb = self.emb(inp)\n",
    "            emb = self.drop(emb)\n",
    "            \n",
    "            state = self.lstm(emb, state)\n",
    "            q_i, _ = state \n",
    "            q_i = self.drop(q_i)\n",
    "\n",
    "            scores = self.clf(q_i)\n",
    "            target = torch.tensor([shifted[i]]).to(device)\n",
    "            loss += self.objective(scores, target)\n",
    "            \n",
    "            curr_token = shifted[i]\n",
    "            \n",
    "        return loss / len(shifted)\n",
    "    \n",
    "    def predict(self, state, curr_token, last_token, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        preds = []\n",
    "        for i in range(maxlen):\n",
    "            inp = torch.tensor([curr_token]).to(device)\n",
    "            \n",
    "            emb = self.emb(inp)\n",
    "            \n",
    "            state = self.lstm(emb, state)\n",
    "            h_i, _ = state\n",
    "            \n",
    "            scores = self.clf(h_i)\n",
    "            pred = torch.argmax(torch.softmax(scores, dim=1))\n",
    "            curr_token = pred\n",
    "            \n",
    "            if last_token == pred:\n",
    "                break\n",
    "            preds.append(pred)\n",
    "            \n",
    "        return preds\n",
    "    \n",
    "    def evaluate(self, state, targets, curr_token, last_token):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        preds, loss = [], 0\n",
    "        shifted = targets + [last_token]\n",
    "        for i in range(len(shifted)):\n",
    "            inp = torch.tensor([curr_token]).to(device)\n",
    "            \n",
    "            emb = self.emb(inp)\n",
    "            \n",
    "            state = self.lstm(emb, state)\n",
    "            h_i, _ = state\n",
    "            \n",
    "            scores = self.clf(h_i)\n",
    "            target = torch.tensor([shifted[i]]).to(device)\n",
    "            loss += self.objective(scores, target)\n",
    "            \n",
    "            pred = torch.argmax(torch.softmax(scores, dim=1))\n",
    "            curr_token = pred\n",
    "            \n",
    "            if last_token == pred:\n",
    "                break\n",
    "            preds.append(pred)\n",
    "            \n",
    "        return preds, loss\n",
    "    \n",
    "decoder = Decoder(vocab_size=len(tgt_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'])\n",
    "saveLogMsg(\"decoder:\\n{}\".format(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            x = sample_x[i]            \n",
    "            x_preds = decoder.predict(encoder(x), START_IX, STOP_IX, pred_size)\n",
    "            predictions.append(x_preds)\n",
    "    \n",
    "    predictions = map_prediction(predictions)\n",
    "    return predictions\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    predictions, sample_loss = [], 0.0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            x = sample_x[i]\n",
    "            y = sample_y[i]\n",
    "            \n",
    "            x_preds, x_loss = decoder.evaluate(encoder(x), y, START_IX, STOP_IX)\n",
    "            predictions.append(x_preds)\n",
    "            sample_loss += x_loss.item()\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    actuals = map_prediction(sample_y)\n",
    "    predictions = map_prediction(predictions)\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "\n",
    "    train_loss, batch_loss = 0.0, 0.0\n",
    "    for i in range(len(train_x)):\n",
    "        x = train_x[i]\n",
    "        y = train_y[i]\n",
    "\n",
    "        batch_loss += decoder(encoder(x), y, START_IX, STOP_IX)\n",
    "        \n",
    "        if (i+1) % batch_size or i == len(train_x) - 1:\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_loss = 0\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, '', patience_track+1\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * ', 0\n",
    "\n",
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=1)\n",
    "    decoder = Decoder(vocab_size=len(tgt_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    patience_track = 0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.zero_grad(); enc_optim.zero_grad()\n",
    "        decoder.zero_grad(); dec_optim.zero_grad()\n",
    "        \n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track, patience_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track)\n",
    "        \n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            epoch_msg = 'Epoch {} - [TRAIN] Loss: {:.6f}'.format(epoch, train_loss)\n",
    "            epoch_msg += ' [DEV] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "            saveLogMsg(epoch_msg + epoch_track)\n",
    "            \n",
    "        if patience_track == int(config['patience']):\n",
    "            saveLogMsg('No accuracy improvment for {} consecutive epochs, stopping training...'.format(config['patience']))\n",
    "            break\n",
    "    \n",
    "    best_encoder, best_decoder, _ = load_best_model()\n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    return best_encoder, best_decoder, keep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with encoder and decoder... \n",
      "\n",
      "Epoch 1 - [TRAIN] Loss: 1.209665 [DEV] Loss: 2.607144, Acc: 0.792800 *  \n",
      "\n",
      "Epoch 2 - [TRAIN] Loss: 0.321942 [DEV] Loss: 0.670059, Acc: 0.953600 *  \n",
      "\n",
      "Epoch 3 - [TRAIN] Loss: 0.159884 [DEV] Loss: 0.285376, Acc: 0.982200 *  \n",
      "\n",
      "Epoch 4 - [TRAIN] Loss: 0.102228 [DEV] Loss: 0.246820, Acc: 0.990400 *  \n",
      "\n",
      "Epoch 5 - [TRAIN] Loss: 0.074495 [DEV] Loss: 0.151441, Acc: 0.993800 *  \n",
      "\n",
      "Epoch 6 - [TRAIN] Loss: 0.065666 [DEV] Loss: 0.109548, Acc: 0.995600 *  \n",
      "\n",
      "Epoch 7 - [TRAIN] Loss: 0.054278 [DEV] Loss: 0.125623, Acc: 0.994800 \n",
      "\n",
      "Epoch 8 - [TRAIN] Loss: 0.043075 [DEV] Loss: 0.117963, Acc: 0.995000 \n",
      "\n",
      "Epoch 9 - [TRAIN] Loss: 0.045605 [DEV] Loss: 0.273130, Acc: 0.991000 \n",
      "\n",
      "Epoch 10 - [TRAIN] Loss: 0.042975 [DEV] Loss: 0.028969, Acc: 0.997600 *  \n",
      "\n",
      "Epoch 11 - [TRAIN] Loss: 0.041695 [DEV] Loss: 0.046155, Acc: 0.998200 *  \n",
      "\n",
      "Epoch 12 - [TRAIN] Loss: 0.043980 [DEV] Loss: 0.101321, Acc: 0.998000 \n",
      "\n",
      "Epoch 13 - [TRAIN] Loss: 0.034407 [DEV] Loss: 0.092175, Acc: 0.995800 \n",
      "\n",
      "Epoch 14 - [TRAIN] Loss: 0.033630 [DEV] Loss: 0.196343, Acc: 0.994400 \n",
      "\n",
      "Epoch 15 - [TRAIN] Loss: 0.029882 [DEV] Loss: 0.088318, Acc: 0.997000 \n",
      "\n",
      "Epoch 16 - [TRAIN] Loss: 0.032743 [DEV] Loss: 0.039499, Acc: 0.998200 \n",
      "\n",
      "Epoch 17 - [TRAIN] Loss: 0.032632 [DEV] Loss: 0.046411, Acc: 0.998400 *  \n",
      "\n",
      "Epoch 18 - [TRAIN] Loss: 0.027445 [DEV] Loss: 0.214197, Acc: 0.997000 \n",
      "\n",
      "Epoch 19 - [TRAIN] Loss: 0.031367 [DEV] Loss: 0.041827, Acc: 0.998600 *  \n",
      "\n",
      "Epoch 20 - [TRAIN] Loss: 0.026408 [DEV] Loss: 0.028390, Acc: 0.998600 \n",
      "\n",
      "Epoch 21 - [TRAIN] Loss: 0.026568 [DEV] Loss: 0.088343, Acc: 0.997400 \n",
      "\n",
      "Epoch 22 - [TRAIN] Loss: 0.027100 [DEV] Loss: 0.051112, Acc: 0.997600 \n",
      "\n",
      "Epoch 23 - [TRAIN] Loss: 0.027711 [DEV] Loss: 0.058750, Acc: 0.996600 \n",
      "\n",
      "Epoch 24 - [TRAIN] Loss: 0.022539 [DEV] Loss: 0.042704, Acc: 0.998400 \n",
      "\n",
      "Epoch 25 - [TRAIN] Loss: 0.024176 [DEV] Loss: 0.049722, Acc: 0.998600 \n",
      "\n",
      "Epoch 26 - [TRAIN] Loss: 0.029720 [DEV] Loss: 0.074904, Acc: 0.998000 \n",
      "\n",
      "Epoch 27 - [TRAIN] Loss: 0.023465 [DEV] Loss: 0.049864, Acc: 0.998200 \n",
      "\n",
      "Epoch 28 - [TRAIN] Loss: 0.022536 [DEV] Loss: 0.027439, Acc: 0.999200 *  \n",
      "\n",
      "Epoch 29 - [TRAIN] Loss: 0.020652 [DEV] Loss: 0.014972, Acc: 0.999200 \n",
      "\n",
      "Epoch 30 - [TRAIN] Loss: 0.023613 [DEV] Loss: 0.025725, Acc: 0.997400 \n",
      "\n",
      "Epoch 31 - [TRAIN] Loss: 0.023241 [DEV] Loss: 0.028068, Acc: 0.999400 *  \n",
      "\n",
      "Epoch 32 - [TRAIN] Loss: 0.019719 [DEV] Loss: 0.050718, Acc: 0.997600 \n",
      "\n",
      "Epoch 33 - [TRAIN] Loss: 0.020528 [DEV] Loss: 0.018076, Acc: 0.999200 \n",
      "\n",
      "Epoch 34 - [TRAIN] Loss: 0.022860 [DEV] Loss: 0.002141, Acc: 0.999600 *  \n",
      "\n",
      "Epoch 35 - [TRAIN] Loss: 0.021236 [DEV] Loss: 0.013733, Acc: 0.998800 \n",
      "\n",
      "Epoch 36 - [TRAIN] Loss: 0.020498 [DEV] Loss: 0.015605, Acc: 0.999600 \n",
      "\n",
      "Epoch 37 - [TRAIN] Loss: 0.016412 [DEV] Loss: 0.044959, Acc: 0.995600 \n",
      "\n",
      "Epoch 38 - [TRAIN] Loss: 0.018236 [DEV] Loss: 0.016791, Acc: 0.999000 \n",
      "\n",
      "Epoch 39 - [TRAIN] Loss: 0.018959 [DEV] Loss: 0.030496, Acc: 0.999400 \n",
      "\n",
      "Epoch 40 - [TRAIN] Loss: 0.017898 [DEV] Loss: 0.006458, Acc: 0.999200 \n",
      "\n",
      "Epoch 41 - [TRAIN] Loss: 0.019181 [DEV] Loss: 0.008292, Acc: 0.999200 \n",
      "\n",
      "Epoch 42 - [TRAIN] Loss: 0.021769 [DEV] Loss: 0.012126, Acc: 0.999200 \n",
      "\n",
      "Epoch 43 - [TRAIN] Loss: 0.019833 [DEV] Loss: 0.023968, Acc: 0.999400 \n",
      "\n",
      "Epoch 44 - [TRAIN] Loss: 0.019840 [DEV] Loss: 0.004692, Acc: 0.999600 \n",
      "\n",
      "No accuracy improvment for 10 consecutive epochs, stopping training... \n",
      "\n",
      "Training done... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True: #not os.path.exists(config['checkpoint']):\n",
    "    saveLogMsg(\"Training with encoder and decoder...\")\n",
    "    training_loop(encoder, decoder, train_x, train_y, config['epoch'], config['batch'], print_every=1)\n",
    "    saveLogMsg('Training done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning best model from epoch 34 with loss 0.002141 and accuracy 0.999600. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "if os.path.exists(config['checkpoint']):\n",
    "    with open(config['lossfile'], 'rb') as lossfile:\n",
    "        keep_loss = pk.load(lossfile)\n",
    "    encoder, decoder, state = load_best_model()\n",
    "    saveLogMsg('Returning best model from epoch {} with loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc']))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training and validation loss... \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveLogMsg('Retrieving training and validation loss...')\n",
    "\n",
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "with open(config['lossfile'], 'rb') as lossfile:\n",
    "    keep_loss = pk.load(lossfile)\n",
    "\n",
    "# Refs: https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset from ../data/raw/test.txt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "saveLogMsg(\"Loading test dataset from {}.\".format(config['testfile']))\n",
    "\n",
    "test_inp, test_out = [], []\n",
    "with open(config['testfile'], 'r') as testfile:\n",
    "    for eachline in testfile:\n",
    "        eachline = eachline.strip()\n",
    "        if eachline:\n",
    "            eachline = eachline.split()\n",
    "            if len(eachline) == 2:\n",
    "                test_inp.append(eachline[0])\n",
    "                test_out.append(eachline[1])\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score = 0.924 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out):\n",
    "    predictions = predict(encoder, decoder, sample_x, config['batch'], config['pred_size'])\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "saveLogMsg(\"Test accuracy score = {}\".format(getAccuracyScore(encoder, decoder, test_x, test_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
