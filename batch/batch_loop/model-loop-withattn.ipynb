{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import _pickle as pk\n",
    "\n",
    "torch.manual_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "import copy, warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing imports and config... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'num_train': 20000,\n",
    "    'num_valid': 5000,\n",
    "    'patience': 10,\n",
    "    'batch': 32,\n",
    "    'epoch': 3000,\n",
    "    'lr': 0.001,\n",
    "    'momentum': 0.99,\n",
    "    'emb_size': 64,\n",
    "    'lstm_size': 128,\n",
    "    'attn_size': 100,\n",
    "    'pred_size': 10,\n",
    "    'testfile': \"../data/raw/test.txt\",\n",
    "    'logfile': \"model_loop_withattn.log\",\n",
    "    'lossfile': 'model_loop_withattn.loss',\n",
    "    'checkpoint': \"model_loop_withattn.pt\"\n",
    "}\n",
    "\n",
    "open(config['logfile'], 'w').close()\n",
    "def saveLogMsg(msg):\n",
    "    print(msg, \"\\n\")\n",
    "    with open(config['logfile'], \"a\") as myfile:\n",
    "        myfile.write(msg + \"\\n\")\n",
    "\n",
    "saveLogMsg(\"Initializing imports and config...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for train and valid... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sorting_letters_dataset(size):\n",
    "    dataset = []\n",
    "    for _ in range(size):\n",
    "        x = []\n",
    "        for _ in range(random.randint(3, 10)):\n",
    "            letter = chr(random.randint(97, 122))\n",
    "            repeat = [letter] * random.randint(1, 3)\n",
    "            x.extend(repeat)\n",
    "        y = sorted(set(x))\n",
    "        dataset.append((x, y))\n",
    "    return zip(*dataset)\n",
    "\n",
    "train_inp, train_out = sorting_letters_dataset(config['num_train'])\n",
    "valid_inp, valid_out = sorting_letters_dataset(config['num_valid'])\n",
    "\n",
    "saveLogMsg(\"Dataset for train and valid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab for source and target... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, vocab):\n",
    "        self.itos = vocab\n",
    "        self.stoi = {d:i for i, d in enumerate(self.itos)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos) \n",
    "\n",
    "src_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)])\n",
    "tgt_vocab = Vocab(['<pad>'] + [chr(i+97) for i in range(26)] + ['<start>', '<stop>'] )\n",
    "\n",
    "START_IX = tgt_vocab.stoi['<start>']\n",
    "STOP_IX  = tgt_vocab.stoi['<stop>']\n",
    "\n",
    "saveLogMsg(\"Vocab for source and target...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dataset through Vocab... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def map_elems(elems, mapper):\n",
    "    return [mapper[elem] for elem in elems]\n",
    "\n",
    "def map_many_elems(many_elems, mapper):\n",
    "    return [map_elems(elems, mapper) for elems in many_elems]\n",
    "\n",
    "train_x = map_many_elems(train_inp, src_vocab.stoi)\n",
    "train_y = map_many_elems(train_out, tgt_vocab.stoi)\n",
    "\n",
    "valid_x = map_many_elems(valid_inp, src_vocab.stoi)\n",
    "valid_y = map_many_elems(valid_out, tgt_vocab.stoi)\n",
    "\n",
    "saveLogMsg(\"Mapping dataset through Vocab...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:\n",
      "Encoder(\n",
      "  (emb): Embedding(27, 64)\n",
      "  (lstm): LSTM(64, 128, batch_first=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, z_type, dropout=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.z_index = z_type\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, lstm_size, batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        device = next(self.parameters()).device\n",
    "        \n",
    "        x_tensor = [torch.tensor(sample).to(device) for sample in inputs]\n",
    "        x_pad = pad_sequence(x_tensor, batch_first=True, padding_value=0) # (batch, seqlen) \n",
    "        x_emb = self.emb(x_pad) # (batch, seqlen, emb_dim) \n",
    "        x_emb = self.drop(x_emb)\n",
    "        \n",
    "        x_len = [len(sample) for sample in inputs]\n",
    "        x_pack = pack_padded_sequence(x_emb, x_len, batch_first=True, enforce_sorted=False)\n",
    "        outs_pack, (h_n, c_n) = self.lstm(x_pack)\n",
    "        outs, _ = pad_packed_sequence(outs_pack, batch_first=True)\n",
    "        \n",
    "        if self.z_index == 1:\n",
    "            return h_n, c_n # (seqlen, batch, lstm_dim)\n",
    "        else:\n",
    "            return outs # (batch, seqlen, lstm_dim)\n",
    "\n",
    "encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=0)\n",
    "saveLogMsg(\"encoder:\\n{}\".format(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, attn_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W = nn.Linear(input_dim, attn_dim)\n",
    "        self.v = nn.Linear(attn_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, dec_hidden, enc_outs):\n",
    "        # enc_outs -> (batch, seqlen, hidden)\n",
    "        # dec_hidden -> (batch, hidden)\n",
    "        \n",
    "        seqlen = enc_outs.size(1)\n",
    "        \n",
    "        repeat_h = dec_hidden.unsqueeze(1)  # make room to repeat on seqlen dim\n",
    "        repeat_h = repeat_h.repeat(1, seqlen, 1)  # (1, seqlen, hidden)\n",
    "\n",
    "        concat_h = torch.cat((enc_outs, repeat_h), dim=2) # (1, seqlen, hidden*2)\n",
    "        \n",
    "        scores = self.v(torch.tanh(self.W(concat_h))) # (1, seqlen, 1)\n",
    "        probs = torch.softmax(scores, dim=1)\n",
    "        \n",
    "        weighted = enc_outs * probs # (1, seqlen, hidden)\n",
    "        \n",
    "        context = torch.sum(weighted, dim=1, keepdim=False) # (1, hidden)\n",
    "        combined = torch.cat((dec_hidden, context), dim=1)  # (1, hidden*2)\n",
    "        \n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder:\n",
      "AttentionDecoder(\n",
      "  (emb): Embedding(29, 64)\n",
      "  (lstm): LSTMCell(64, 128)\n",
      "  (attn): Attention(\n",
      "    (W): Linear(in_features=256, out_features=100, bias=True)\n",
      "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
      "  )\n",
      "  (clf): Linear(in_features=256, out_features=29, bias=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (objective): CrossEntropyLoss()\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, lstm_size, attn_size, dropout=0.5):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        \n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTMCell(emb_dim, lstm_size)\n",
    "        self.attn = Attention(lstm_size * 2, attn_size)\n",
    "        self.clf = nn.Linear(lstm_size * 2, vocab_size)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.objective = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        \n",
    "    def init_state(self, device):\n",
    "        h_0 = torch.zeros(1, self.lstm_size).to(device)  # (batch, hidden_size)\n",
    "        c_0 = torch.zeros(1, self.lstm_size).to(device)  # (batch, hidden_size)\n",
    "        return h_0, c_0\n",
    "        \n",
    "    def forward(self, batch_outs, batch_targets, curr_token_raw, last_token_raw):\n",
    "        device = next(self.parameters()).device\n",
    "        state = self.init_state(device)\n",
    "        \n",
    "        batch_loss = 0.0\n",
    "        for enc_outs, targets in zip(batch_outs, batch_targets):\n",
    "            curr_token, last_token = curr_token_raw, last_token_raw\n",
    "            shifted = targets + [last_token]\n",
    "            \n",
    "            enc_outs = torch.unsqueeze(enc_outs, 0) # (1, seqlen, lstm_dim)\n",
    "            \n",
    "            each_loss = 0.0\n",
    "            for i in range(len(shifted)):\n",
    "                inp = torch.tensor([curr_token]).to(device)\n",
    "\n",
    "                emb = self.emb(inp)\n",
    "                emb = self.drop(emb)\n",
    "\n",
    "                state = self.lstm(emb, state)\n",
    "                q_i, _ = state \n",
    "                q_i = self.drop(q_i)\n",
    "                \n",
    "                combined = self.attn(q_i, enc_outs)\n",
    "\n",
    "                scores = self.clf(combined)\n",
    "                target = torch.tensor([shifted[i]]).to(device)\n",
    "                each_loss += self.objective(scores, target)\n",
    "\n",
    "                curr_token = shifted[i]\n",
    "                \n",
    "            batch_loss += (each_loss / len(shifted) * 1.0)\n",
    "\n",
    "        return batch_loss\n",
    "\n",
    "    def predict(self, batch_outs, curr_token_raw, last_token_raw, maxlen):\n",
    "        device = next(self.parameters()).device\n",
    "        state = self.init_state(device)\n",
    "        \n",
    "        batch_preds = []\n",
    "        for enc_outs in batch_outs:\n",
    "            curr_token, last_token = curr_token_raw, last_token_raw\n",
    "            \n",
    "            enc_outs = torch.unsqueeze(enc_outs, 0) # (1, seqlen, lstm_dim)\n",
    "            \n",
    "            each_preds = []\n",
    "            for i in range(maxlen):\n",
    "                inp = torch.tensor([curr_token]).to(device)\n",
    "                \n",
    "                emb = self.emb(inp)\n",
    "\n",
    "                state = self.lstm(emb, state)\n",
    "                q_i, _ = state\n",
    "\n",
    "                combined = self.attn(q_i, enc_outs)\n",
    "\n",
    "                scores = self.clf(combined)\n",
    "                pred = torch.argmax(torch.softmax(scores, dim=1))\n",
    "                curr_token = pred\n",
    "\n",
    "                if last_token == pred:\n",
    "                    break\n",
    "                each_preds.append(pred)\n",
    "                \n",
    "            batch_preds.append(each_preds)\n",
    "            \n",
    "        return batch_preds\n",
    "    \n",
    "    def evaluate(self, batch_outs, batch_targets, curr_token_raw, last_token_raw):\n",
    "        device = next(self.parameters()).device\n",
    "        state = self.init_state(device)\n",
    "        \n",
    "        batch_preds = []\n",
    "        batch_loss = 0.0\n",
    "        for enc_outs, targets in zip(batch_outs, batch_targets):\n",
    "            curr_token, last_token = curr_token_raw, last_token_raw\n",
    "            shifted = targets + [last_token]\n",
    "            \n",
    "            enc_outs = torch.unsqueeze(enc_outs, 0) # (1, seqlen, lstm_dim)\n",
    "            \n",
    "            each_preds = []\n",
    "            each_loss = 0.0\n",
    "            for i in range(len(shifted)):\n",
    "                inp = torch.tensor([curr_token]).to(device)\n",
    "                \n",
    "                emb = self.emb(inp)\n",
    "\n",
    "                state = self.lstm(emb, state)\n",
    "                q_i, _ = state\n",
    "\n",
    "                combined = self.attn(q_i, enc_outs)\n",
    "\n",
    "                scores = self.clf(combined)\n",
    "                target = torch.tensor([shifted[i]]).to(device)\n",
    "                each_loss += self.objective(scores, target)\n",
    "                \n",
    "                pred = torch.argmax(torch.softmax(scores, dim=1))\n",
    "                curr_token = pred\n",
    "\n",
    "                if last_token == pred:\n",
    "                    break\n",
    "                each_preds.append(pred)\n",
    "                \n",
    "            batch_loss += (each_loss / len(each_preds) * 1.0)\n",
    "            batch_preds.append(each_preds)\n",
    "            \n",
    "        return batch_preds, batch_loss\n",
    "\n",
    "decoder = AttentionDecoder(vocab_size=len(tgt_vocab), \n",
    "                           emb_dim=config['emb_size'], \n",
    "                           lstm_size=config['lstm_size'], \n",
    "                           attn_size=config['attn_size'])\n",
    "saveLogMsg(\"decoder:\\n{}\".format(decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prediction(sample_preds):\n",
    "    sample_preds = [[tgt_vocab.itos[ix] for ix in each_preds] for each_preds in sample_preds]\n",
    "    sample_preds = [''.join(each_preds) for each_preds in sample_preds]\n",
    "    return sample_preds\n",
    "\n",
    "def predict(encoder, decoder, sample_x, batch_size, pred_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    batch_x = []\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds = decoder.predict(encoder(batch_x), START_IX, STOP_IX, pred_size)\n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_x = []\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "def evaluate(encoder, decoder, sample_x, sample_y, batch_size):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    sample_loss = 0.0\n",
    "    batch_x, batch_y = [], []\n",
    "    predictions, actuals = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sample_x)):\n",
    "            batch_x.append(sample_x[i])\n",
    "            batch_y.append(sample_y[i])\n",
    "            \n",
    "            if len(batch_x) == batch_size or i == len(sample_x) - 1:\n",
    "                batch_preds, batch_loss = decoder.evaluate(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "                \n",
    "                batch_preds = map_prediction(batch_preds)\n",
    "                predictions.extend(batch_preds)\n",
    "                batch_y = map_prediction(batch_y)\n",
    "                actuals.extend(batch_y)\n",
    "                \n",
    "                sample_loss += batch_loss.item()\n",
    "                batch_x, batch_y = [], []\n",
    "    \n",
    "    sample_loss = sample_loss / len(sample_x) * 1.0\n",
    "    \n",
    "    accuracy = accuracy_score(actuals, predictions)\n",
    "    return predictions, sample_loss, accuracy\n",
    "\n",
    "def train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_x, train_y = shuffle(train_x, train_y)\n",
    "    batch_x, batch_y = [], []\n",
    "\n",
    "    for i in range(len(train_x)):\n",
    "        batch_x.append(train_x[i])\n",
    "        batch_y.append(train_y[i])\n",
    "\n",
    "        if len(batch_x) == batch_size or i == len(train_x) - 1:\n",
    "            batch_loss = decoder(encoder(batch_x), batch_y, START_IX, STOP_IX)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            enc_optim.step()\n",
    "            dec_optim.step()\n",
    "\n",
    "            encoder.zero_grad(); enc_optim.zero_grad()\n",
    "            decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "            train_loss += batch_loss.item()\n",
    "            batch_x, batch_y = [], []\n",
    "\n",
    "    train_loss = train_loss / len(train_x) * 1.0\n",
    "    \n",
    "    return encoder, decoder, train_x, train_y, train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    pack = list(zip(x, y))\n",
    "    random.shuffle(pack)\n",
    "    return zip(*pack)\n",
    "\n",
    "def track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track):\n",
    "    if best_acc >= valid_acc:\n",
    "        return best_acc, '', patience_track+1\n",
    "    state = {\n",
    "        'encoder': encoder.state_dict(), \n",
    "        'decoder': decoder.state_dict(),\n",
    "        'acc': valid_acc,\n",
    "        'loss': valid_loss,\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(state, config['checkpoint'])\n",
    "    return valid_acc, ' * ', 0\n",
    "\n",
    "def load_best_model():\n",
    "    encoder = Encoder(vocab_size=len(src_vocab), \n",
    "                  emb_dim=config['emb_size'], \n",
    "                  lstm_size=config['lstm_size'], \n",
    "                  z_type=0)\n",
    "    decoder = AttentionDecoder(vocab_size=len(tgt_vocab), \n",
    "                               emb_dim=config['emb_size'], \n",
    "                               lstm_size=config['lstm_size'], \n",
    "                               attn_size=config['attn_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    state = torch.load(config['checkpoint'], map_location=device)\n",
    "    encoder.load_state_dict(state['encoder'])\n",
    "    decoder.load_state_dict(state['decoder'])\n",
    "    state = {'acc': state['acc'], 'loss': state['loss'], 'epoch': state['epoch']}\n",
    "    return encoder, decoder, state\n",
    "\n",
    "def training_loop(encoder, decoder, train_x, train_y, epochs, batch_size, print_every=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    enc_optim = optim.SGD(encoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    dec_optim = optim.SGD(decoder.parameters(), lr=config['lr'], momentum=config['momentum'])\n",
    "    \n",
    "    best_acc = -1.0\n",
    "    patience_track = 0\n",
    "    keep_loss = [[], []] # [[train],[valid]]\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.zero_grad(); enc_optim.zero_grad()\n",
    "        decoder.zero_grad(); dec_optim.zero_grad()\n",
    "\n",
    "        encoder, decoder, train_x, train_y, train_loss = train(encoder, enc_optim, decoder, dec_optim, train_x, train_y, batch_size)\n",
    "        _, valid_loss, valid_acc = evaluate(encoder, decoder, valid_x, valid_y, batch_size)\n",
    "        best_acc, epoch_track, patience_track = track_best_model(encoder, decoder, epoch, best_acc, valid_acc, valid_loss, patience_track)\n",
    "\n",
    "        keep_loss[0].append(train_loss)\n",
    "        keep_loss[1].append(valid_loss)\n",
    "        \n",
    "        if epoch % print_every == 0:\n",
    "            epoch_msg = 'Epoch {} - [TRAIN] Loss: {:.6f}'.format(epoch, train_loss)\n",
    "            epoch_msg += ' [DEV] Loss: {:.6f}, Acc: {:.6f}'.format(valid_loss, valid_acc)\n",
    "            saveLogMsg(epoch_msg + epoch_track)\n",
    "            \n",
    "        if patience_track == int(config['patience']):\n",
    "            saveLogMsg('No accuracy improvment for {} consecutive epochs, stopping training...'.format(config['patience']))\n",
    "            break\n",
    "    \n",
    "    best_encoder, best_decoder, _ = load_best_model()\n",
    "    with open(config['lossfile'], 'wb') as lossfile:\n",
    "        pk.dump(keep_loss, lossfile)\n",
    "    \n",
    "    return best_encoder, best_decoder, keep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with encoder and decoder... \n",
      "\n",
      "Epoch 1 - [TRAIN] Loss: 1.334294 [DEV] Loss: 1.639361, Acc: 0.731000 *  \n",
      "\n",
      "Epoch 2 - [TRAIN] Loss: 0.280049 [DEV] Loss: 0.397180, Acc: 0.950200 *  \n",
      "\n",
      "Epoch 3 - [TRAIN] Loss: 0.156487 [DEV] Loss: 0.389296, Acc: 0.955800 *  \n",
      "\n",
      "Epoch 4 - [TRAIN] Loss: 0.112903 [DEV] Loss: 0.106048, Acc: 0.986600 *  \n",
      "\n",
      "Epoch 5 - [TRAIN] Loss: 0.095927 [DEV] Loss: 0.164523, Acc: 0.984800 \n",
      "\n",
      "Epoch 6 - [TRAIN] Loss: 0.078040 [DEV] Loss: 0.116765, Acc: 0.986800 *  \n",
      "\n",
      "Epoch 7 - [TRAIN] Loss: 0.070175 [DEV] Loss: 0.053506, Acc: 0.995200 *  \n",
      "\n",
      "Epoch 8 - [TRAIN] Loss: 0.064225 [DEV] Loss: 0.091975, Acc: 0.990400 \n",
      "\n",
      "Epoch 9 - [TRAIN] Loss: 0.066525 [DEV] Loss: 0.089906, Acc: 0.993000 \n",
      "\n",
      "Epoch 10 - [TRAIN] Loss: 0.061094 [DEV] Loss: 0.047794, Acc: 0.995000 \n",
      "\n",
      "Epoch 11 - [TRAIN] Loss: 0.054753 [DEV] Loss: 0.023334, Acc: 0.997200 *  \n",
      "\n",
      "Epoch 12 - [TRAIN] Loss: 0.062597 [DEV] Loss: 0.089637, Acc: 0.992200 \n",
      "\n",
      "Epoch 13 - [TRAIN] Loss: 0.060567 [DEV] Loss: 0.042978, Acc: 0.996800 \n",
      "\n",
      "Epoch 14 - [TRAIN] Loss: 0.051922 [DEV] Loss: 0.100222, Acc: 0.994600 \n",
      "\n",
      "Epoch 15 - [TRAIN] Loss: 0.045768 [DEV] Loss: 0.105567, Acc: 0.992400 \n",
      "\n",
      "Epoch 16 - [TRAIN] Loss: 0.042691 [DEV] Loss: 0.035045, Acc: 0.997600 *  \n",
      "\n",
      "Epoch 17 - [TRAIN] Loss: 0.041573 [DEV] Loss: 0.054696, Acc: 0.995400 \n",
      "\n",
      "Epoch 18 - [TRAIN] Loss: 0.039159 [DEV] Loss: 0.046080, Acc: 0.996600 \n",
      "\n",
      "Epoch 19 - [TRAIN] Loss: 0.044883 [DEV] Loss: 0.047190, Acc: 0.995600 \n",
      "\n",
      "Epoch 20 - [TRAIN] Loss: 0.042556 [DEV] Loss: 0.040229, Acc: 0.997600 \n",
      "\n",
      "Epoch 21 - [TRAIN] Loss: 0.041390 [DEV] Loss: 0.024971, Acc: 0.998400 *  \n",
      "\n",
      "Epoch 22 - [TRAIN] Loss: 0.044821 [DEV] Loss: 0.027519, Acc: 0.997800 \n",
      "\n",
      "Epoch 23 - [TRAIN] Loss: 0.041139 [DEV] Loss: 0.044644, Acc: 0.997400 \n",
      "\n",
      "Epoch 24 - [TRAIN] Loss: 0.042896 [DEV] Loss: 0.053891, Acc: 0.996400 \n",
      "\n",
      "Epoch 25 - [TRAIN] Loss: 0.041412 [DEV] Loss: 0.028254, Acc: 0.997000 \n",
      "\n",
      "Epoch 26 - [TRAIN] Loss: 0.038593 [DEV] Loss: 0.024877, Acc: 0.998000 \n",
      "\n",
      "Epoch 27 - [TRAIN] Loss: 0.039666 [DEV] Loss: 0.045479, Acc: 0.996600 \n",
      "\n",
      "Epoch 28 - [TRAIN] Loss: 0.041924 [DEV] Loss: 0.022417, Acc: 0.998800 *  \n",
      "\n",
      "Epoch 29 - [TRAIN] Loss: 0.044058 [DEV] Loss: 0.023769, Acc: 0.998400 \n",
      "\n",
      "Epoch 30 - [TRAIN] Loss: 0.044821 [DEV] Loss: 0.024659, Acc: 0.998800 \n",
      "\n",
      "Epoch 31 - [TRAIN] Loss: 0.042058 [DEV] Loss: 0.029102, Acc: 0.998000 \n",
      "\n",
      "Epoch 32 - [TRAIN] Loss: 0.040756 [DEV] Loss: 0.021994, Acc: 0.998000 \n",
      "\n",
      "Epoch 33 - [TRAIN] Loss: 0.039592 [DEV] Loss: 0.017816, Acc: 0.998400 \n",
      "\n",
      "Epoch 34 - [TRAIN] Loss: 0.041546 [DEV] Loss: 0.014103, Acc: 0.999200 *  \n",
      "\n",
      "Epoch 35 - [TRAIN] Loss: 0.042684 [DEV] Loss: 0.020694, Acc: 0.998000 \n",
      "\n",
      "Epoch 36 - [TRAIN] Loss: 0.037710 [DEV] Loss: 0.037002, Acc: 0.997800 \n",
      "\n",
      "Epoch 37 - [TRAIN] Loss: 0.037801 [DEV] Loss: 0.024811, Acc: 0.998800 \n",
      "\n",
      "Epoch 38 - [TRAIN] Loss: 0.041943 [DEV] Loss: 0.014272, Acc: 0.998600 \n",
      "\n",
      "Epoch 39 - [TRAIN] Loss: 0.041368 [DEV] Loss: 0.049542, Acc: 0.994400 \n",
      "\n",
      "Epoch 40 - [TRAIN] Loss: 0.042811 [DEV] Loss: 0.085430, Acc: 0.995600 \n",
      "\n",
      "Epoch 41 - [TRAIN] Loss: 0.039095 [DEV] Loss: 0.015671, Acc: 0.998200 \n",
      "\n",
      "Epoch 42 - [TRAIN] Loss: 0.038519 [DEV] Loss: 0.016178, Acc: 0.998600 \n",
      "\n",
      "Epoch 43 - [TRAIN] Loss: 0.036320 [DEV] Loss: 0.005720, Acc: 0.999600 *  \n",
      "\n",
      "Epoch 44 - [TRAIN] Loss: 0.038561 [DEV] Loss: 0.010729, Acc: 0.999400 \n",
      "\n",
      "Epoch 45 - [TRAIN] Loss: 0.038460 [DEV] Loss: 0.024490, Acc: 0.998200 \n",
      "\n",
      "Epoch 46 - [TRAIN] Loss: 0.040625 [DEV] Loss: 0.021574, Acc: 0.996200 \n",
      "\n",
      "Epoch 47 - [TRAIN] Loss: 0.041044 [DEV] Loss: 0.011533, Acc: 0.999400 \n",
      "\n",
      "Epoch 48 - [TRAIN] Loss: 0.039237 [DEV] Loss: 0.026343, Acc: 0.998600 \n",
      "\n",
      "Epoch 49 - [TRAIN] Loss: 0.038346 [DEV] Loss: 0.006566, Acc: 0.999000 \n",
      "\n",
      "Epoch 50 - [TRAIN] Loss: 0.040536 [DEV] Loss: 0.006474, Acc: 0.999400 \n",
      "\n",
      "Epoch 51 - [TRAIN] Loss: 0.044927 [DEV] Loss: 0.023323, Acc: 0.998200 \n",
      "\n",
      "Epoch 52 - [TRAIN] Loss: 0.036901 [DEV] Loss: 0.010295, Acc: 0.999000 \n",
      "\n",
      "Epoch 53 - [TRAIN] Loss: 0.039104 [DEV] Loss: 0.026676, Acc: 0.998600 \n",
      "\n",
      "No accuracy improvment for 10 consecutive epochs, stopping training... \n",
      "\n",
      "Training done... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(config['checkpoint']):\n",
    "    saveLogMsg(\"Training with encoder and decoder...\")\n",
    "    training_loop(encoder, decoder, train_x, train_y, config['epoch'], config['batch'], print_every=1)\n",
    "    saveLogMsg('Training done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning best model from epoch 43 with loss 0.005720 and accuracy 0.999600. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "keep_loss = [[], []] # [[train],[valid]]\n",
    "if os.path.exists(config['checkpoint']):\n",
    "    with open(config['lossfile'], 'rb') as lossfile:\n",
    "        keep_loss = pk.load(lossfile)\n",
    "    encoder, decoder, state = load_best_model()\n",
    "    saveLogMsg('Returning best model from epoch {} with loss {:.6f} and accuracy {:.6f}.'.format(state['epoch'], state['loss'], state['acc'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training and validation loss... \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveLogMsg('Retrieving training and validation loss...')\n",
    "\n",
    "# Refs: https://matplotlib.org/tutorials/introductory/pyplot.html\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = [i for i in range(1, len(keep_loss[0])+1)]\n",
    "plt.plot(epochs, keep_loss[0], 'b', label=\"training loss\")\n",
    "plt.plot(epochs, keep_loss[1], 'g', label=\"validation loss\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('cross-entropy loss')\n",
    "plt.title('The training and validation losses.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset from ../data/raw/test.txt. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "saveLogMsg(\"Loading test dataset from {}.\".format(config['testfile']))\n",
    "\n",
    "test_inp, test_out = [], []\n",
    "with open(config['testfile'], 'r') as testfile:\n",
    "    for eachline in testfile:\n",
    "        eachline = eachline.strip()\n",
    "        if eachline:\n",
    "            eachline = eachline.split()\n",
    "            if len(eachline) == 2:\n",
    "                test_inp.append(eachline[0])\n",
    "                test_out.append(eachline[1])\n",
    "test_x = map_many_elems(test_inp, src_vocab.stoi)\n",
    "test_y = map_many_elems(test_out, tgt_vocab.stoi)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score = 0.9254 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getAccuracyScore(encoder, decoder, sample_x, sample_out):\n",
    "    predictions = predict(encoder, decoder, sample_x, config['batch'], config['pred_size'])\n",
    "    groundtruth = [''.join(str_y) for str_y in sample_out]\n",
    "    acc = accuracy_score(groundtruth, predictions)\n",
    "    return acc\n",
    "\n",
    "saveLogMsg(\"Test accuracy score = {}\".format(getAccuracyScore(encoder, decoder, test_x, test_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
